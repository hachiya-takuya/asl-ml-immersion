{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7fcfe6-f8c8-46e2-b5d1-1c8354697664",
   "metadata": {},
   "source": [
    "# Deploying a Streamlit Image Classification App on Google Cloud Run\n",
    "\n",
    "This guide provides you with the scaffold and steps to build a simple image classification application using Streamlit.\n",
    "\n",
    "\n",
    "### What is Streamlit?\n",
    "[Streamlit](https://streamlit.io/) is an open-source Python library that's become the go-to tool for quickly creating interactive web applications, especially for data science and machine learning projects.  Streamlit's intuitive design makes it easy to build powerful apps with minimal code.\n",
    "\n",
    "Check out the amazing examples in the [Streamlit Gallery](https://streamlit.io/gallery) to see the wide range of applications you can create. From data dashboards and visualizations to machine learning demos and interactive tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cfef51-ca96-40fa-9aee-c0a9a28bd07a",
   "metadata": {},
   "source": [
    "This notebook doesn't require an accelerator, but optionally you can attach a GPU to speed up the training process below.<br>\n",
    "(It takes more than 15 minutes to train without a GPU. Or you can stop the training in the middle just to simply deploy the application.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf0c10d-628f-4445-8279-9826377d048a",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f24596-e86b-4d18-8c60-12b973c3720c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfdb0c-2462-4b1b-8059-4ad82d6ecaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from google.cloud import aiplatform\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3a625-c626-4fad-b6b0-794f3a937e27",
   "metadata": {},
   "source": [
    "## Building an Image Classification Model\n",
    "\n",
    "We'll create a flower image classification model using the 5-Flower dataset as an example.\n",
    "\n",
    "If you want to know more about the code below, please check [../../../notebooks/image_models/solutions/3_tf_hub_transfer_learning.ipynb](https://github.com/GoogleCloudPlatform/asl-ml-immersion/blob/master/notebooks/image_models/solutions/3_tf_hub_transfer_learning.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad47080-ad70-4a5d-a1c3-72a5ea72b841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT + \"-flowers\"\n",
    "FILE_DIR = f\"gs://{BUCKET}/data\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "\n",
    "CLASSES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab3d7e-968c-4d43-9050-da9217deb48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "\n",
    "if [ -n \"$exists\" ]; then\n",
    "    echo -e \"Bucket exists, let's not recreate it.\"\n",
    "    \n",
    "else\n",
    "    echo \"Creating a new GCS bucket.\"\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "    echo \"Here are your current buckets:\"\n",
    "    gsutil ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d79872-0f6a-4da1-9f48-e6c2b9ceb1db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gsutil cp gs://asl-public/data/flowers/tfrecords/* {FILE_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991066f4-a7c5-43f9-ab5d-f7a6122153f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATTERN = FILE_DIR + \"/train*\"\n",
    "EVAL_PATTERN = FILE_DIR + \"/eval*\"\n",
    "\n",
    "\n",
    "def parse_example(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "    example[\"image\"] = tf.image.resize(\n",
    "        example[\"image\"], [IMG_HEIGHT, IMG_WIDTH]\n",
    "    )\n",
    "    example[\"image\"] = example[\"image\"] / 255\n",
    "    return example[\"image\"], example[\"label\"]\n",
    "\n",
    "\n",
    "train_ds = (\n",
    "    tf.data.TFRecordDataset(tf.io.gfile.glob(TRAIN_PATTERN))\n",
    "    .map(parse_example)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "eval_ds = (\n",
    "    tf.data.TFRecordDataset(tf.io.gfile.glob(EVAL_PATTERN))\n",
    "    .map(parse_example)\n",
    "    .batch(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed44e32-0bfe-4bac-aa2d-ed11037cbac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "module_selection = \"mobilenet_v2_100_224\"\n",
    "module_handle = \"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(\n",
    "    module_selection\n",
    ")\n",
    "\n",
    "transfer_model = tf.keras.Sequential(\n",
    "    [\n",
    "        hub.KerasLayer(module_handle, trainable=True),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(\n",
    "            len(CLASSES),\n",
    "            activation=\"softmax\",\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transfer_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c678e44-d4fb-4ccf-9921-eba43ad88f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transfer_model.fit(\n",
    "    train_ds,\n",
    "    epochs=5,\n",
    "    validation_data=eval_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1aad20-f834-4d5a-969a-6690e71df3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"export\", ignore_errors=True)\n",
    "os.mkdir(\"export\")\n",
    "transfer_model.save(\"export/flowers_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aaeee0-2563-487c-95ab-4ebb4d94c9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls export/flowers_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c4033-a7c3-41b5-991b-3fbee6a37583",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8b040-a64a-4925-bd96-123185f4c66f",
   "metadata": {},
   "source": [
    "## Build a streamlit application\n",
    "\n",
    "With our image classification model prepared, let's create a Streamlit app to make it interactive and user-friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441f6b6-bca9-4aad-95f9-84a53fc2119a",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "First, we'll import the necessary Python libraries, including Streamlit itself, as well as any other libraries needed for image processing and model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faaa4f9-7c12-4d59-bb00-d78afd65aecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\"\"\"Streamlit Image Classification App\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d32d88-ae75-4b73-9856-f15aa26f7cfc",
   "metadata": {},
   "source": [
    "### Add text elements\n",
    "Streamlit eventually renders a web page, but we can simply use Python modules to define and configure the the web page elements.\n",
    "\n",
    "We'll start by configuring some metadata for our app.\n",
    "\n",
    "- [`st.set_page_config`](https://docs.streamlit.io/develop/api-reference/configuration/st.set_page_config) lets us customize aspects like the page title and favicon (the little icon that appears in your browser tab).\n",
    "\n",
    "Streamlit provides a variety of ways to display text content:\n",
    "- [`st.title`](https://docs.streamlit.io/develop/api-reference/text/st.title) is used to add a main heading to our page.\n",
    "- You can also use [`st.header`](https://docs.streamlit.io/develop/api-reference/text/st.header) and [`st.subheader`](https://docs.streamlit.io/develop/api-reference/text/st.subheader) for smaller headings.\n",
    "- [`st.text`](https://docs.streamlit.io/develop/api-reference/text/st.text) is for displaying plain text.\n",
    "- [`st.markdown`](https://docs.streamlit.io/develop/api-reference/text/st.markdown) lets you add formatted text using Markdown syntax.\n",
    "For more options, you can check the Streamlit documentation for [other text elements](https://docs.streamlit.io/develop/api-reference/text).\n",
    "\n",
    "Streamlit also offer a \"swiss-army knife\" command called [`st.write`](https://docs.streamlit.io/develop/api-reference/write-magic/st.write). It can handle many types of content, including text, DataFrames (tables of data), Matplotlib plots, and even Keras machine learning models.\n",
    "\n",
    "Also, here we define a few global variables that we'll use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb068578-b530-4baa-a57d-b06571696076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "st.set_page_config(page_title=\"5-Flower Classifier\", page_icon=\"🌷\")\n",
    "\n",
    "st.title(\"5-Flower Classifier\")\n",
    "\n",
    "st.markdown(\n",
    "    \"Welcome to this simple web application that classifies 5 flowers\"\n",
    "    + \"(daisy, dandelion, roses, sunflowers, tulips).\"\n",
    ")\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "CLASSES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331b92b-7831-47c1-bc29-e59352a63991",
   "metadata": {},
   "source": [
    "### Defining Model Loading with Caching\n",
    "\n",
    "We'll define a function to load our image classification model using `keras.models.load_model`.\n",
    "\n",
    "To avoid reloading the model every time we make a prediction, we'll use the [`@st.cache_resource`](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.cache_resource) decorator. This decorator caches the output of our function, making it much faster to access the model on subsequent runs.\n",
    "\n",
    "**Note: [`@st.cache_resource`](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.cache_resource) is best suited for global objects that can't be easily serialized (converted to a simple data format), such as database connections or complex machine learning models. For simpler, serializable objects (like pandas DataFrames), you might consider using [`tf.cache_data`](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.cache_data) instead.**\n",
    "\n",
    "For a deeper dive into caching and how to optimize your Streamlit apps, you can check out [this document](https://docs.streamlit.io/develop/concepts/architecture/caching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caedbe2-e09d-4bfb-a73b-d39672e1aab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "@st.cache_resource(show_spinner=False)\n",
    "def load_and_cache_model():\n",
    "    model_path = \"flowers_model\"\n",
    "    model = load_model(model_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99894c68-0067-44fa-9339-2b565cd9c819",
   "metadata": {},
   "source": [
    "### Defining Utility Functions\n",
    "\n",
    "We also define a few utility functions .\n",
    "\n",
    "To prepare images for our model and interpret its predictions, we'll define a few helper functions for model serving, like image decoding and rescaling, resizing, and post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e91a5c-412c-4837-b853-a7dd5c16c235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "def read_image(img_bytes):\n",
    "    img = tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict(model, image):\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    predictions = model.predict(image)\n",
    "    pred_index = np.argmax(predictions[0])\n",
    "    return predictions[0][pred_index], CLASSES[pred_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bc680-d929-47bf-aa35-2deefb275c15",
   "metadata": {},
   "source": [
    "### Defining the Application Logic\n",
    "\n",
    "Now let's  the main application logic.\n",
    "\n",
    "We design an application that has these capabilities:\n",
    "1. **Upload image**: We'll use [`st.file_uploader`](https://docs.streamlit.io/develop/api-reference/widgets/st.file_uploader) to create a widget that allows users to select and upload an image file. We can specify allowed file types (like PNG or JPG) to guide the user\n",
    "2. **Show the uploaded image**: Once an image is uploaded, we'll display it using [`st.image`](https://docs.streamlit.io/develop/api-reference/media/st.image). Alternatively, the versatile [`tf.write`](https://docs.streamlit.io/develop/api-reference/write-magic/st.write) function can also handle image display.\n",
    "3. **Start image classification**: We'll create a button labeled \"Classify\" using [`st.button`](https://docs.streamlit.io/develop/api-reference/widgets/st.button), which returns `True` when it is pushed. (For more advanced button use cases, like stateful buttons, you can refer to the Streamlit documentation: https://docs.streamlit.io/develop/concepts/design/buttons).\n",
    "4. **Call the classification model**: We'll use our previously defined functions to load the model and make a prediction. Since this might take a moment, we'll wrap it in a with [`with st.spinner`](https://docs.streamlit.io/develop/api-reference/status/st.spinner) block to provide visual feedback to the user that the process is underway.\n",
    "5. **Show the result**: Once the model generates a prediction, we'll display it to the user. We'll use [`st.success`](https://docs.streamlit.io/develop/api-reference/status/st.success) to clearly indicate that the classification was completed successfully, along with the predicted flower type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5050eb-2130-4c9e-ada4-08d001551ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile -a app.py\n",
    "\n",
    "def main():\n",
    "    file_uploaded = st.file_uploader(\"Choose File\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "    if file_uploaded is not None:\n",
    "        image = read_image(file_uploaded.read())\n",
    "        st.image(image.numpy(), caption=\"Uploaded Image\", use_column_width=True)\n",
    "        class_btn = st.button(\"Classify\")\n",
    "        if class_btn:\n",
    "            with st.spinner(\"Model predicting....\"):\n",
    "                loaded_model = load_and_cache_model()\n",
    "                prob, prediction = predict(loaded_model, image)\n",
    "                st.success(f\"Prediction: {prediction} - {prob:.2%}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c0808-5299-4527-9df5-1492beb7d9d5",
   "metadata": {},
   "source": [
    "## Deploying the App on Cloud Run\n",
    "Our Streamlit application is ready! Let's deploy it to Google Cloud Run, a serverless platform designed to run containerized applications seamlessly.\n",
    "\n",
    "### Defining Dockerfile and Dependencies\n",
    "To containerize our app for Cloud Run, we define `requirements.txt` and `Dockerfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5418e-937e-4c34-9996-3e96f51bf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "numpy==1.23.5\n",
    "streamlit==1.30.0\n",
    "tensorflow==2.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4c8a7-7f63-450d-8301-4fa4af53ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.10.14\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt /app\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY export /app\n",
    "COPY app.py /app\n",
    "\n",
    "EXPOSE 8080\n",
    "\n",
    "CMD streamlit run --server.port 8080 --server.enableCORS false app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d25e8-7171-47b5-ab9e-5053fad20b6a",
   "metadata": {},
   "source": [
    "**Note: We've split the `COPY` command into multiple lines, each copying different files. Although this is not required, this is a crucial optimization for Docker's caching mechanism.<br> If you make changes only to app.py, the next time you build the image, Docker will reuse the cached layers for the dependency installation and other files, speeding up the build process significantly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e22c5-e73b-42d3-97c9-bed2011b2812",
   "metadata": {},
   "source": [
    "### Building and Pushing the Container to Artifact Registry\n",
    "Now that we have our `Dockerfile`, we can build the Docker image of our Streamlit app and push it to Google Cloud's Artifact Registry. \n",
    "Artifact Registry offers a secure and scalable way to store your container images.\n",
    "\n",
    "First, we'll create a new repository in Artifact Registry to house our container image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e950b-396a-4fd5-83c2-4ec400d0611f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STREAMLIT_ARTIFACT_REG_REPO = \"flower-classification-app\"\n",
    "os.environ[\"STREAMLIT_ARTIFACT_REG_REPO\"] = STREAMLIT_ARTIFACT_REG_REPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85dcad-4dc1-4fb2-926c-bf19826d57e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gcloud artifacts repositories describe $STREAMLIT_ARTIFACT_REG_REPO \\\n",
    "       --location=$REGION > /dev/null 2>&1; then\n",
    "    gcloud artifacts repositories create $STREAMLIT_ARTIFACT_REG_REPO \\\n",
    "        --project=$PROJECT --location=$REGION --repository-format=docker\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a7418-ad96-420f-bfdc-06f83a142df5",
   "metadata": {},
   "source": [
    "### Defining cloudbuild.yaml for Cloud Build\n",
    "We'll use Google Cloud Build to automate the process of building our Docker image and pushing it to Artifact Registry. \n",
    "\n",
    "Cloud Build is a serverless CI/CD platform that lets you define build steps in a configuration file called cloudbuild.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec83318-31ac-4d2b-b4c2-10028b2b9c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTAINER_PATH = (\n",
    "    f\"us-central1-docker.pkg.dev/{PROJECT}/{STREAMLIT_ARTIFACT_REG_REPO}/app\"\n",
    ")\n",
    "os.environ[\"CONTAINER_PATH\"] = CONTAINER_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67075a-0864-429b-8be8-0fdf052a70c9",
   "metadata": {},
   "source": [
    "Here's a cloudbuild.yaml file that incorporates caching to make our builds faster:\n",
    "\n",
    "1. **Pull Existing Image**: The first step attempts to pull the latest version of your Docker image from Artifact Registry. Here we use `bash -c` command as the entrypoint so that the job can ignore and proceed even if this step fails in the first run.\n",
    "2. **Build with Caching**: The second step builds the new image. `--cache-from` flag tells Docker to use the layers from the pulled image as a cache, speeding up the build if there are no changes to those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82177b1a-7d4f-4a4e-9fb6-409a7c868414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile cloudbuild.yaml\n",
    "steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  entrypoint: 'bash'\n",
    "  args: ['-c', 'docker pull ${_CONTAINER_PATH}:latest || exit 0']\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: [\n",
    "            'build',\n",
    "            '-t', '${_CONTAINER_PATH}:latest',\n",
    "            '--cache-from', '${_CONTAINER_PATH}:latest',\n",
    "            '.'\n",
    "        ]\n",
    "images: ['${_CONTAINER_PATH}:latest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c4542-ec7e-497a-b3b4-4d7dabf68561",
   "metadata": {},
   "source": [
    "### Building the Container Image\n",
    "\n",
    "With our cloudbuild.yaml file defined, we can now instruct Cloud Build to construct our Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b54f0-8e7a-4a5c-8fb0-fb684e944676",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --config cloudbuild.yaml --region $REGION . --substitutions _CONTAINER_PATH={CONTAINER_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212e426-57d5-4f5b-93a4-4295344cf0b9",
   "metadata": {},
   "source": [
    "### Deploying to Cloud Run\n",
    "With our container image stored in Artifact Registry is ready, we're all set to deploy our Streamlit app to Cloud Run.\n",
    "\n",
    "You can also consider incorporating this command into the `cloudbuild.yaml` we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a852ea-cc32-4a63-8838-e97ba4b8bbd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "APP_NAME = \"flower-classification\"\n",
    "os.environ[\"APP_NAME\"] = APP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64fe98-c1d4-4454-b1b8-f3a6800e4b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo 'Deploying the application to Cloud Run...'\n",
    "gcloud run deploy $APP_NAME \\\n",
    "  --image $CONTAINER_PATH:latest --min-instances 1 --max-instances 1 --cpu 1 \\\n",
    "  --memory 4Gi --region us-central1 > /dev/null 2>&1 && \\\n",
    "echo 'Deployment Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf51f5-6703-4a7f-aebc-ac32dfda24eb",
   "metadata": {},
   "source": [
    "### Connect to Cloud Run app via Cloud Shell\n",
    "\n",
    "\n",
    "You have a lot of flexibility when it comes to configuring access to your Cloud Run service. You can even [make it publicly accessible](https://cloud.google.com/run/docs/authenticating/public) if you want to.\n",
    "\n",
    "However, for this example, let's see how to connect to your Cloud Run app securely from Cloud Shell using a proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9840eb6-5f47-45b3-a156-e7b96849d97e",
   "metadata": {},
   "source": [
    "Follow these steps to open the app from Cloud Shell.\n",
    "1. Run the next cell, copy the output `gcloud run services proxy ...`command.\n",
    "2. Open Cloud Shell, paste and run the command.\n",
    "3. In Cloud Shell, click the \"Web Preview\" button on the toolbar.\n",
    "4. Select \"Preview on port 8080\"\n",
    "5. A new browser tab or window will open, displaying your Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57754f-c055-4cb4-8175-338336e5bfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"gcloud run services proxy {APP_NAME} --project {PROJECT} --region {REGION}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9501082-c0b3-46ab-b55f-b825f41dacf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prediction\n",
    "Now you're ready to test your model.\n",
    "\n",
    "Search for a clear image of one of the flower types your model recognizes (daisy, dandelion, rose, sunflower, or tulip), upload your image and click \"Classify.\" <br>\n",
    "The app will display the predicted flower type!\n",
    "\n",
    "The first access and prediction may take some time, but it'll be faster from the second time thanks to the cache.\n",
    "\n",
    "<img width=\"1004\" alt=\"image\" src=\"https://github.com/GoogleCloudPlatform/asl-ml-immersion/assets/6895245/4b6fd594-69fd-491e-9ca2-c199d3cb66a7\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcef05-35c8-4d1a-bb4b-4217c1a84020",
   "metadata": {},
   "source": [
    "Copyright 2024 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b564ae4-6a39-46c7-a328-9c904da1412a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
