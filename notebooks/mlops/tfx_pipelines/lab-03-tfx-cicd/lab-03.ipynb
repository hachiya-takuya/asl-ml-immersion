{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CI/CD for TFX pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1.  Develop a CI/CD workflow with Cloud Build to build and deploy a machine learning pipeline.\n",
    "2.  Integrate with Github to trigger workflows with pipeline source repository changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will walk through authoring a Cloud Build CI/CD workflow that automatically builds and deploys the same TFX pipeline from `lab-02.ipynb`. You will also integrate your workflow with GitHub by setting up a trigger that starts the workflow when a new tag is applied to the GitHub repo hosting the pipeline's code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/jupyter/.local/bin:/home/jupyter/.local/bin:/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Set `PATH` to include the directory containing TFX CLI.\n",
    "PATH=%env PATH\n",
    "%env PATH=/home/jupyter/.local/bin:{PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 0.21.4\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tfx; print('TFX version: {}'.format(tfx.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: this lab was built and tested with the following package versions:\n",
    "\n",
    "`TFX version: 0.21.4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) If the TFX version above does not match the lab tested defaults, run the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --user tfx==0.21.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: you may need to restart the kernel to pick up the correct package versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Cloud Build workflow\n",
    "Review the `cloudbuild.yaml` file to understand how the CI/CD workflow is implemented and how environment specific settings are abstracted using **Cloud Build** variables.\n",
    "\n",
    "The **Cloud Build** CI/CD workflow automates the steps you walked through manually during `lab-02`:\n",
    "1. Builds the custom TFX image to be used as a runtime execution environment for TFX components and as the AI Platform Training training container.\n",
    "1. Compiles the pipeline and uploads the pipeline to the KFP environment\n",
    "1. Pushes the custom TFX image to your project's **Container Registry**\n",
    "\n",
    "The **Cloud Build** workflow configuration uses both standard and custom [Cloud Build builders](https://cloud.google.com/cloud-build/docs/cloud-builders). The custom builder encapsulates **TFX CLI**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring environment settings\n",
    "\n",
    "Navigate to [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) page in the Google Cloud Console.\n",
    "\n",
    "**1.  Create or select an existing Kubernetes cluster (GKE) and deploy AI Platform**. Make sure to select `\"Allow access to the following Cloud APIs https://www.googleapis.com/auth/cloud-platform\"` to allow for programmatic access to your pipeline by the Kubeflow SDK for the rest of the lab. Also, provide an `App instance name` such as \"tfx\" or \"mlops\". Note you may have already deployed an AI Pipelines instance during the Setup for the lab series. If so, you can proceed using that instance below in the next step.\n",
    "\n",
    "Validate the deployment of your AI Platform Pipelines instance in the console before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Configuring environment settings**\n",
    "\n",
    "Update  the below constants  with the settings reflecting your lab environment. \n",
    "\n",
    "- `GCP_REGION` - the compute region for AI Platform Training and Prediction\n",
    "- `ARTIFACT_STORE` - the GCS bucket created during installation of AI Platform Pipelines. The bucket name starts with the `kubeflowpipelines-` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://artifacts.qwiklabs-gcp-ml-a65a6543b5a6.appspot.com/\n",
      "gs://qwiklabs-gcp-ml-a65a6543b5a6-kubeflowpipelines-default/\n"
     ]
    }
   ],
   "source": [
    "# Use the following command to identify the GCS bucket for metadata and pipeline storage.\n",
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ENDPOINT` - set the `ENDPOINT` constant to the endpoint to your AI Platform Pipelines instance. The endpoint to the AI Platform Pipelines instance can be found on the [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) page in the Google Cloud Console. Open the *SETTINGS* for your instance and use the value of the `host` variable in the *Connect to this Kubeflow Pipelines instance from a Python client via Kubeflow Pipelines SKD* section of the *SETTINGS* window. The format is `'....[region].pipelines.googleusercontent.com'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_REGION = 'us-central1'\n",
    "ARTIFACT_STORE_URI = 'gs://qwiklabs-gcp-ml-a65a6543b5a6-kubeflowpipelines-default'\n",
    "ENDPOINT = 'a56ba690a399e62-dot-us-central2.pipelines.googleusercontent.com'\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the TFX CLI builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.  Review the Dockerfile describing the TFX CLI builder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-1\n",
      "COPY requirements.txt .\n",
      "RUN python -m pip install -U -r requirements.txt\n",
      "\n",
      "ENTRYPOINT [\"tfx\"]\n"
     ]
    }
   ],
   "source": [
    "!cat tfx-cli/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas<1.0.0\n",
      "tfx==0.21.4\n",
      "kfp==0.5.1\n"
     ]
    }
   ],
   "source": [
    "!cat tfx-cli/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.  Build the image and push it to your project's Container Registry**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the [Cloud Build](https://cloud.google.com/cloud-build/docs/running-builds/start-build-manually#gcloud) gcloud command line reference for builds submit. Your image should follow the format `gcr.io/[PROJECT_ID]/[IMAGE_NAME]:latest`. Note the source code for the tfx-cli is in the directory `./tfx-cli`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='tfx-cli'\n",
    "TAG='latest'\n",
    "IMAGE_URI='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 2 file(s) totalling 183 bytes before compression.\n",
      "Uploading tarball of [tfx-cli] to [gs://qwiklabs-gcp-ml-a65a6543b5a6_cloudbuild/source/1601157917.968755-26d539764cae482492e4ae909858ac58.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-gcp-ml-a65a6543b5a6/builds/3c92bcc3-a573-441d-b485-d23416c17fdb].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/3c92bcc3-a573-441d-b485-d23416c17fdb?project=438920459488].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"3c92bcc3-a573-441d-b485-d23416c17fdb\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-gcp-ml-a65a6543b5a6_cloudbuild/source/1601157917.968755-26d539764cae482492e4ae909858ac58.tgz#1601157918950837\n",
      "Copying gs://qwiklabs-gcp-ml-a65a6543b5a6_cloudbuild/source/1601157917.968755-26d539764cae482492e4ae909858ac58.tgz#1601157918950837...\n",
      "/ [1 files][  295.0 B/  295.0 B]                                                \n",
      "Operation completed over 1 objects/295.0 B.                                      \n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  3.072kB\n",
      "Step 1/4 : FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-1\n",
      "latest: Pulling from deeplearning-platform-release/tf2-cpu.2-1\n",
      "f08d8e2a3ba1: Already exists\n",
      "3baa9cb2483b: Already exists\n",
      "94e5ff4c0b15: Already exists\n",
      "1860925334f9: Already exists\n",
      "aa0346bca052: Pulling fs layer\n",
      "2cdc52730f79: Pulling fs layer\n",
      "0ba0de3bfc57: Pulling fs layer\n",
      "cfc189ad1b0c: Pulling fs layer\n",
      "1696c6152326: Pulling fs layer\n",
      "b326b9dc9e3d: Pulling fs layer\n",
      "e48245ee4473: Pulling fs layer\n",
      "4681b4568019: Pulling fs layer\n",
      "c3fc7eed71d1: Pulling fs layer\n",
      "3c383b737d47: Pulling fs layer\n",
      "4d58cc5455cb: Pulling fs layer\n",
      "7cc98672bd98: Pulling fs layer\n",
      "8a5f50f1df88: Pulling fs layer\n",
      "3e3ff802ef42: Pulling fs layer\n",
      "a1212d691646: Pulling fs layer\n",
      "cfc189ad1b0c: Waiting\n",
      "1696c6152326: Waiting\n",
      "b326b9dc9e3d: Waiting\n",
      "e48245ee4473: Waiting\n",
      "4681b4568019: Waiting\n",
      "c3fc7eed71d1: Waiting\n",
      "3c383b737d47: Waiting\n",
      "4d58cc5455cb: Waiting\n",
      "7cc98672bd98: Waiting\n",
      "8a5f50f1df88: Waiting\n",
      "3e3ff802ef42: Waiting\n",
      "a1212d691646: Waiting\n",
      "0ba0de3bfc57: Verifying Checksum\n",
      "0ba0de3bfc57: Download complete\n",
      "2cdc52730f79: Verifying Checksum\n",
      "2cdc52730f79: Download complete\n",
      "1696c6152326: Verifying Checksum\n",
      "1696c6152326: Download complete\n",
      "b326b9dc9e3d: Verifying Checksum\n",
      "b326b9dc9e3d: Download complete\n",
      "e48245ee4473: Verifying Checksum\n",
      "e48245ee4473: Download complete\n",
      "4681b4568019: Verifying Checksum\n",
      "4681b4568019: Download complete\n",
      "c3fc7eed71d1: Verifying Checksum\n",
      "c3fc7eed71d1: Download complete\n",
      "cfc189ad1b0c: Verifying Checksum\n",
      "cfc189ad1b0c: Download complete\n",
      "3c383b737d47: Verifying Checksum\n",
      "3c383b737d47: Download complete\n",
      "4d58cc5455cb: Verifying Checksum\n",
      "4d58cc5455cb: Download complete\n",
      "7cc98672bd98: Verifying Checksum\n",
      "7cc98672bd98: Download complete\n",
      "3e3ff802ef42: Verifying Checksum\n",
      "3e3ff802ef42: Download complete\n",
      "a1212d691646: Verifying Checksum\n",
      "a1212d691646: Download complete\n",
      "aa0346bca052: Verifying Checksum\n",
      "aa0346bca052: Download complete\n",
      "8a5f50f1df88: Verifying Checksum\n",
      "8a5f50f1df88: Download complete\n",
      "aa0346bca052: Pull complete\n",
      "2cdc52730f79: Pull complete\n",
      "0ba0de3bfc57: Pull complete\n",
      "cfc189ad1b0c: Pull complete\n",
      "1696c6152326: Pull complete\n",
      "b326b9dc9e3d: Pull complete\n",
      "e48245ee4473: Pull complete\n",
      "4681b4568019: Pull complete\n",
      "c3fc7eed71d1: Pull complete\n",
      "3c383b737d47: Pull complete\n",
      "4d58cc5455cb: Pull complete\n",
      "7cc98672bd98: Pull complete\n",
      "8a5f50f1df88: Pull complete\n",
      "3e3ff802ef42: Pull complete\n",
      "a1212d691646: Pull complete\n",
      "Digest: sha256:543a1e0ab9e2cd8be1b05dd59c9584eefc0de495474ebb0b5a32f870eb3ddfd2\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-cpu.2-1:latest\n",
      " ---> ac51cd7745e0\n",
      "Step 2/4 : COPY requirements.txt .\n",
      " ---> 38aa187e2018\n",
      "Step 3/4 : RUN python -m pip install -U -r requirements.txt\n",
      " ---> Running in d169a017dc44\n",
      "Collecting pandas<1.0.0\n",
      "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
      "Requirement already up-to-date: tfx==0.21.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.21.4)\n",
      "Collecting kfp==0.5.1\n",
      "  Downloading kfp-0.5.1.tar.gz (119 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas<1.0.0->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.0.0->-r requirements.txt (line 1)) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas<1.0.0->-r requirements.txt (line 1)) (2020.1)\n",
      "Collecting kubernetes<11,>=10.0.1\n",
      "  Downloading kubernetes-10.1.0-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied, skipping upgrade: ml-metadata<0.22,>=0.21.2 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (0.21.2)\n",
      "Collecting pyarrow<0.16,>=0.15\n",
      "  Downloading pyarrow-0.15.1-cp37-cp37m-manylinux2010_x86_64.whl (59.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: six<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py<0.9,>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: apache-beam[gcp]<2.18,>=2.17 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (2.17.0)\n",
      "Requirement already satisfied, skipping upgrade: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2<3,>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow<3,>=1.15 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: docker<5,>=4.1 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (4.3.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-transform<0.22,>=0.21.2 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (0.21.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf<4,>=3.7 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-serving-api<3,>=1.15 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml<6,>=5 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio!=1.27.2,<2,>=1.25 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (1.32.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-data-validation<0.22,>=0.21.4 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (0.21.5)\n",
      "Requirement already satisfied, skipping upgrade: click<8,>=7 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: tfx-bsl<0.22,>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (0.21.4)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-model-analysis<0.22,>=0.21.4 in /opt/conda/lib/python3.7/site-packages (from tfx==0.21.4->-r requirements.txt (line 2)) (0.21.6)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp==0.5.1->-r requirements.txt (line 3)) (1.30.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp==0.5.1->-r requirements.txt (line 3)) (1.21.2)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /opt/conda/lib/python3.7/site-packages (from kfp==0.5.1->-r requirements.txt (line 3)) (1.6.0)\n",
      "Collecting kfp-server-api<0.6.0,>=0.2.5\n",
      "  Downloading kfp-server-api-0.5.0.tar.gz (39 kB)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp==0.5.1->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /opt/conda/lib/python3.7/site-packages (from kfp==0.5.1->-r requirements.txt (line 3)) (0.8.7)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting strip-hints\n",
      "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.24.2 in /opt/conda/lib/python3.7/site-packages (from kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=14.05.14 in /opt/conda/lib/python3.7/site-packages (from kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (50.3.0)\n",
      "Requirement already satisfied, skipping upgrade: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (2.5.8)\n",
      "Requirement already satisfied, skipping upgrade: avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: dill<0.3.1,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (0.3.0)\n",
      "Collecting httplib2<=0.12.0,>=0.8\n",
      "  Downloading httplib2-0.12.0.tar.gz (218 kB)\n",
      "Requirement already satisfied, skipping upgrade: oauth2client<4,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pydot<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: future<1.0.0,>=0.16.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (1.7)\n",
      "Requirement already satisfied, skipping upgrade: fastavro<0.22,>=0.21.4 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (0.21.24)\n",
      "Requirement already satisfied, skipping upgrade: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (3.11.0)\n",
      "Collecting mock<3.0.0,>=1.0.1\n",
      "  Downloading mock-2.0.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"\n",
      "  Downloading google_cloud_bigtable-1.0.0-py2.py3-none-any.whl (232 kB)\n",
      "Collecting google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_pubsub-1.0.2-py2.py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (1.3.0)\n",
      "Collecting cachetools<4,>=3.1.0; extra == \"gcp\"\n",
      "  Downloading cachetools-3.1.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied, skipping upgrade: google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" in /opt/conda/lib/python3.7/site-packages (from apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (0.5.28)\n",
      "Collecting google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"\n",
      "  Downloading google_cloud_bigquery-1.17.1-py2.py3-none-any.whl (142 kB)\n",
      "Collecting google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"\n",
      "  Downloading google_cloud_datastore-1.7.4-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->tfx==0.21.4->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->tfx==0.21.4->-r requirements.txt (line 2)) (1.22.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->tfx==0.21.4->-r requirements.txt (line 2)) (0.0.3)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2<3,>=2.7.3->tfx==0.21.4->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing==1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (2.1.1)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-metadata<0.22,>=0.21 in /opt/conda/lib/python3.7/site-packages (from tensorflow-transform<0.22,>=0.21.2->tfx==0.21.4->-r requirements.txt (line 2)) (0.21.2)\n",
      "Collecting joblib<0.15,>=0.12\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Collecting scikit-learn<0.22,>=0.18\n",
      "  Downloading scikit_learn-0.21.3-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=5 in /opt/conda/lib/python3.7/site-packages (from tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (7.18.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter<2,>=1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets<8,>=7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==0.5.1->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.5.1->-r requirements.txt (line 3)) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.5.1->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.5.1->-r requirements.txt (line 3)) (0.17.3)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.5.1->-r requirements.txt (line 3)) (20.2.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.5.1->-r requirements.txt (line 3)) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kubernetes<11,>=10.0.1->tfx==0.21.4->-r requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: docopt in /opt/conda/lib/python3.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from pydot<2,>=1.2.0->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: pbr>=0.11 in /opt/conda/lib/python3.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (5.5.0)\n",
      "Requirement already satisfied, skipping upgrade: grpc-google-iam-v1<0.13dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (0.12.3)\n",
      "Requirement already satisfied, skipping upgrade: fasteners>=0.14 in /opt/conda/lib/python3.7/site-packages (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (0.15)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.7.8->tfx==0.21.4->-r requirements.txt (line 2)) (1.52.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<3,>=1.15->tfx==0.21.4->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (3.0.7)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: pexpect>4.3; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (2.7.1)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (5.0.4)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (5.6.1)\n",
      "Requirement already satisfied, skipping upgrade: notebook in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (6.1.4)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-console in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (6.2.0)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (5.3.4)\n",
      "Requirement already satisfied, skipping upgrade: qtconsole in /opt/conda/lib/python3.7/site-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (4.7.7)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (5.0.7)\n",
      "Requirement already satisfied, skipping upgrade: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage>=1.13.0->kfp==0.5.1->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp==0.5.1->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: monotonic>=0.1 in /opt/conda/lib/python3.7/site-packages (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<2.18,>=2.17->tfx==0.21.4->-r requirements.txt (line 2)) (1.5)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=5->tensorflow-data-validation<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (20.1.0)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=5.0 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=5.3.4 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (6.1.7)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (19.0.2)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: qtpy in /opt/conda/lib/python3.7/site-packages (from qtconsole->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage>=1.13.0->kfp==0.5.1->-r requirements.txt (line 3)) (1.14.3)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.22,>=0.21.4->tfx==0.21.4->-r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-storage>=1.13.0->kfp==0.5.1->-r requirements.txt (line 3)) (2.20)\n",
      "Building wheels for collected packages: kfp, kfp-server-api, strip-hints, httplib2\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-0.5.1-py3-none-any.whl size=162118 sha256=7399f909d710789753a5b69d6ce4a5e3ef018438b878d00b36078d255154dbf5\n",
      "  Stored in directory: /root/.cache/pip/wheels/00/76/1a/a59903334e8fb128c1e43aca2eca1ac16eca783ef21fdd9d62\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-0.5.0-py3-none-any.whl size=105483 sha256=8b10d4b54f7a5f4d76e2b56548f95bc196425d8d36db208e4af6ca223510aeba\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/a7/1d/4ffad43cd2dc75429ec61d760b40d2741311b430ea118918c6\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20994 sha256=a74a1950c15e5705a2213ac4607e3b6957e34f8ecc94f43119a75795bf6b3bb3\n",
      "  Stored in directory: /root/.cache/pip/wheels/2d/b8/4e/a3ec111d2db63cec88121bd7c0ab1a123bce3b55dd19dda5c1\n",
      "  Building wheel for httplib2 (setup.py): started\n",
      "  Building wheel for httplib2 (setup.py): finished with status 'done'\n",
      "  Created wheel for httplib2: filename=httplib2-0.12.0-py3-none-any.whl size=93464 sha256=0156f74fb1786b96bcf8973e12aaf0df288111c820646b213aba1a40c215d0f6\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/e7/b6/0dd30343ceca921cfbd91f355041bd9c69e0f40b49f25b7b8a\n",
      "Successfully built kfp kfp-server-api strip-hints httplib2\n",
      "Installing collected packages: pandas, kubernetes, requests-toolbelt, kfp-server-api, Deprecated, strip-hints, kfp, pyarrow, httplib2, mock, google-cloud-bigtable, google-cloud-pubsub, cachetools, google-cloud-bigquery, google-cloud-datastore, scipy, joblib, scikit-learn\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.2\n",
      "    Uninstalling pandas-1.1.2:\n",
      "      Successfully uninstalled pandas-1.1.2\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 11.0.0\n",
      "    Uninstalling kubernetes-11.0.0:\n",
      "      Successfully uninstalled kubernetes-11.0.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 1.0.1\n",
      "    Uninstalling pyarrow-1.0.1:\n",
      "      Successfully uninstalled pyarrow-1.0.1\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.18.1\n",
      "    Uninstalling httplib2-0.18.1:\n",
      "      Successfully uninstalled httplib2-0.18.1\n",
      "  Attempting uninstall: mock\n",
      "    Found existing installation: mock 4.0.2\n",
      "    Uninstalling mock-4.0.2:\n",
      "      Successfully uninstalled mock-4.0.2\n",
      "  Attempting uninstall: google-cloud-bigtable\n",
      "    Found existing installation: google-cloud-bigtable 1.4.0\n",
      "    Uninstalling google-cloud-bigtable-1.4.0:\n",
      "      Successfully uninstalled google-cloud-bigtable-1.4.0\n",
      "  Attempting uninstall: google-cloud-pubsub\n",
      "    Found existing installation: google-cloud-pubsub 1.7.0\n",
      "    Uninstalling google-cloud-pubsub-1.7.0:\n",
      "      Successfully uninstalled google-cloud-pubsub-1.7.0\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 4.1.1\n",
      "    Uninstalling cachetools-4.1.1:\n",
      "      Successfully uninstalled cachetools-4.1.1\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 1.26.1\n",
      "    Uninstalling google-cloud-bigquery-1.26.1:\n",
      "      Successfully uninstalled google-cloud-bigquery-1.26.1\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 1.12.0\n",
      "    Uninstalling google-cloud-datastore-1.12.0:\n",
      "      Successfully uninstalled google-cloud-datastore-1.12.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.16.0\n",
      "    Uninstalling joblib-0.16.0:\n",
      "      Successfully uninstalled joblib-0.16.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.2\n",
      "    Uninstalling scikit-learn-0.23.2:\n",
      "      Successfully uninstalled scikit-learn-0.23.2\n",
      "\u001b[91mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-io 0.11.0 requires tensorflow==2.1.0, but you'll have tensorflow 2.1.1 which is incompatible.\n",
      "kubernetes 10.1.0 requires pyyaml~=3.12, but you'll have pyyaml 5.3.1 which is incompatible.\n",
      "google-cloud-bigquery 1.17.1 requires google-resumable-media<0.5.0dev,>=0.3.1, but you'll have google-resumable-media 1.0.0 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.10 cachetools-3.1.1 google-cloud-bigquery-1.17.1 google-cloud-bigtable-1.0.0 google-cloud-datastore-1.7.4 google-cloud-pubsub-1.0.2 httplib2-0.12.0 joblib-0.14.1 kfp-0.5.1 kfp-server-api-0.5.0 kubernetes-10.1.0 mock-2.0.0 pandas-0.25.3 pyarrow-0.15.1 requests-toolbelt-0.9.1 scikit-learn-0.21.3 scipy-1.4.1 strip-hints-0.1.9\n",
      "Removing intermediate container d169a017dc44\n",
      " ---> e3a3aa12e2ca\n",
      "Step 4/4 : ENTRYPOINT [\"tfx\"]\n",
      " ---> Running in 62839f5ec32e\n",
      "Removing intermediate container 62839f5ec32e\n",
      " ---> 2e9dcc15d3de\n",
      "Successfully built 2e9dcc15d3de\n",
      "Successfully tagged gcr.io/qwiklabs-gcp-ml-a65a6543b5a6/tfx-cli:latest\n",
      "PUSH\n",
      "Pushing gcr.io/qwiklabs-gcp-ml-a65a6543b5a6/tfx-cli:latest\n",
      "The push refers to repository [gcr.io/qwiklabs-gcp-ml-a65a6543b5a6/tfx-cli]\n",
      "41541051c0ab: Preparing\n",
      "a461019093a7: Preparing\n",
      "51d931e6a1c4: Preparing\n",
      "f252eaf8c7f0: Preparing\n",
      "026f54427db8: Preparing\n",
      "5a80f706027a: Preparing\n",
      "56e9ed080402: Preparing\n",
      "6763155ca840: Preparing\n",
      "03b47b86a5e7: Preparing\n",
      "e5a3e5ae9870: Preparing\n",
      "96306392a604: Preparing\n",
      "608d6c8834f0: Preparing\n",
      "e268755738fb: Preparing\n",
      "b1872abfad9d: Preparing\n",
      "711d45b5a6f6: Preparing\n",
      "f25965f9e300: Preparing\n",
      "5b9320a62e9d: Preparing\n",
      "001e4a80973b: Preparing\n",
      "2ba5b91ca2b0: Preparing\n",
      "2f37d1102187: Preparing\n",
      "79bde4d54386: Preparing\n",
      "5a80f706027a: Waiting\n",
      "56e9ed080402: Waiting\n",
      "6763155ca840: Waiting\n",
      "03b47b86a5e7: Waiting\n",
      "e5a3e5ae9870: Waiting\n",
      "96306392a604: Waiting\n",
      "608d6c8834f0: Waiting\n",
      "e268755738fb: Waiting\n",
      "b1872abfad9d: Waiting\n",
      "711d45b5a6f6: Waiting\n",
      "f25965f9e300: Waiting\n",
      "5b9320a62e9d: Waiting\n",
      "001e4a80973b: Waiting\n",
      "2ba5b91ca2b0: Waiting\n",
      "2f37d1102187: Waiting\n",
      "79bde4d54386: Waiting\n",
      "026f54427db8: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "51d931e6a1c4: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "f252eaf8c7f0: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "a461019093a7: Pushed\n",
      "5a80f706027a: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "56e9ed080402: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "6763155ca840: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "03b47b86a5e7: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "e5a3e5ae9870: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "96306392a604: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "608d6c8834f0: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "e268755738fb: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "b1872abfad9d: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "711d45b5a6f6: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "001e4a80973b: Layer already exists\n",
      "f25965f9e300: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "5b9320a62e9d: Mounted from deeplearning-platform-release/tf2-cpu.2-1\n",
      "79bde4d54386: Layer already exists\n",
      "2ba5b91ca2b0: Layer already exists\n",
      "2f37d1102187: Layer already exists\n",
      "41541051c0ab: Pushed\n",
      "latest: digest: sha256:409281b94d73e8e6d5f1ad277d2ee8652d2eb675cba95fc39c3de1c057ad6c9f size: 4713\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                 STATUS\n",
      "3c92bcc3-a573-441d-b485-d23416c17fdb  2020-09-26T22:05:19+00:00  4M49S     gs://qwiklabs-gcp-ml-a65a6543b5a6_cloudbuild/source/1601157917.968755-26d539764cae482492e4ae909858ac58.tgz  gcr.io/qwiklabs-gcp-ml-a65a6543b5a6/tfx-cli (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout 15m --tag {IMAGE_URI} tfx-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: manually trigger CI/CD pipeline run with Cloud Build\n",
    "\n",
    "You can manually trigger **Cloud Build** runs using the `gcloud builds submit` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME='tfx_covertype_continuous_training'\n",
    "TAG_NAME='test'\n",
    "TFX_IMAGE_NAME='lab-03-tfx-image'\n",
    "DATA_ROOT_URI='gs://workshop-datasets/covertype/small'\n",
    "MODEL_NAME='tfx_covertype_classifier'\n",
    "PIPELINE_FOLDER='pipeline'\n",
    "PIPELINE_DSL='runner.py'\n",
    "RUNTIME_VERSION='2.1'\n",
    "PYTHON_VERSION='3.7'\n",
    "USE_KFP_SA='False'\n",
    "\n",
    "SUBSTITUTIONS=\"\"\"\n",
    "_ENDPOINT={},\\\n",
    "_GCP_REGION={},\\\n",
    "_ARTIFACT_STORE_URI={},\\\n",
    "_TFX_IMAGE_NAME={},\\\n",
    "_DATA_ROOT_URI={},\\\n",
    "_MODEL_NAME={},\\\n",
    "TAG_NAME={},\\\n",
    "_PIPELINE_FOLDER={},\\\n",
    "_PIPELINE_DSL={},\\\n",
    "_PIPELINE_NAME={},\\\n",
    "_RUNTIME_VERSION={},\\\n",
    "_USE_KFP_SA={},\\\n",
    "_PYTHON_VERSION={}\n",
    "\"\"\".format(ENDPOINT, \n",
    "           GCP_REGION, \n",
    "           ARTIFACT_STORE_URI, \n",
    "           TFX_IMAGE_NAME,\n",
    "           DATA_ROOT_URI,\n",
    "           MODEL_NAME,\n",
    "           TAG_NAME, \n",
    "           PIPELINE_FOLDER,\n",
    "           PIPELINE_DSL,\n",
    "           PIPELINE_NAME,\n",
    "           RUNTIME_VERSION,\n",
    "           PYTHON_VERSION,\n",
    "           USE_KFP_SA\n",
    "           ).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: you can manually trigger **Cloud Build** runs using the `gcloud builds submit` command. See the [documentation](https://cloud.google.com/sdk/gcloud/reference/builds/submit) for pass the `cloudbuild.yaml` file and SUBSTITIONS as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 28 file(s) totalling 153.0 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://qwiklabs-gcp-ml-a65a6543b5a6_cloudbuild/source/1601158210.662011-56350cd0a8a74318accca3359c18054e.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-gcp-ml-a65a6543b5a6/builds/ef51b542-8a55-4ab1-b82d-3cf49e40650a].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/ef51b542-8a55-4ab1-b82d-3cf49e40650a?project=438920459488].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"ef51b542-8a55-4ab1-b82d-3cf49e40650a\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-gcp-ml-a65a6543b5a6_cloudbuild/source/1601158210.662011-56350cd0a8a74318accca3359c18054e.tgz#1601158211075120\n",
      "Copying gs://qwiklabs-gcp-ml-a65a6543b5a6_cloudbuild/source/1601158210.662011-56350cd0a8a74318accca3359c18054e.tgz#1601158211075120...\n",
      "/ [1 files][ 26.7 KiB/ 26.7 KiB]                                                \n",
      "Operation completed over 1 objects/26.7 KiB.                                     \n",
      "BUILD\n",
      "Starting Step #0\n",
      "Step #0: Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Step #0: Sending build context to Docker daemon   34.3kB\n",
      "Step #0: Step 1/4 : FROM tensorflow/tfx:0.21.4\n",
      "Step #0: 0.21.4: Pulling from tensorflow/tfx\n",
      "Step #0: bd47987755ba: Pulling fs layer\n",
      "Step #0: 831c222b21d8: Pulling fs layer\n",
      "Step #0: 3c2cba919283: Pulling fs layer\n",
      "Step #0: e378d88a5f59: Pulling fs layer\n",
      "Step #0: df37508d2f5c: Pulling fs layer\n",
      "Step #0: bd5056198be8: Pulling fs layer\n",
      "Step #0: 044a6cc327bc: Pulling fs layer\n",
      "Step #0: c7411e31635f: Pulling fs layer\n",
      "Step #0: 29aa6e9dcc22: Pulling fs layer\n",
      "Step #0: 9777e791df93: Pulling fs layer\n",
      "Step #0: 9adf91901ea3: Pulling fs layer\n",
      "Step #0: 1bb0820f7158: Pulling fs layer\n",
      "Step #0: 8aa238cf5652: Pulling fs layer\n",
      "Step #0: b57d894b9e7f: Pulling fs layer\n",
      "Step #0: e378d88a5f59: Waiting\n",
      "Step #0: df37508d2f5c: Waiting\n",
      "Step #0: bd5056198be8: Waiting\n",
      "Step #0: 044a6cc327bc: Waiting\n",
      "Step #0: c7411e31635f: Waiting\n",
      "Step #0: 29aa6e9dcc22: Waiting\n",
      "Step #0: 9777e791df93: Waiting\n",
      "Step #0: 9adf91901ea3: Waiting\n",
      "Step #0: 1bb0820f7158: Waiting\n",
      "Step #0: 8aa238cf5652: Waiting\n",
      "Step #0: b57d894b9e7f: Waiting\n",
      "Step #0: 3c2cba919283: Verifying Checksum\n",
      "Step #0: 3c2cba919283: Download complete\n",
      "Step #0: 831c222b21d8: Verifying Checksum\n",
      "Step #0: 831c222b21d8: Download complete\n",
      "Step #0: bd47987755ba: Verifying Checksum\n",
      "Step #0: bd47987755ba: Download complete\n",
      "Step #0: e378d88a5f59: Verifying Checksum\n",
      "Step #0: e378d88a5f59: Download complete\n",
      "Step #0: bd5056198be8: Verifying Checksum\n",
      "Step #0: bd5056198be8: Download complete\n",
      "Step #0: c7411e31635f: Verifying Checksum\n",
      "Step #0: c7411e31635f: Download complete\n",
      "Step #0: 044a6cc327bc: Verifying Checksum\n",
      "Step #0: 044a6cc327bc: Download complete\n",
      "Step #0: df37508d2f5c: Verifying Checksum\n",
      "Step #0: df37508d2f5c: Download complete\n",
      "Step #0: 9adf91901ea3: Verifying Checksum\n",
      "Step #0: 9adf91901ea3: Download complete\n",
      "Step #0: 9777e791df93: Verifying Checksum\n",
      "Step #0: 9777e791df93: Download complete\n",
      "Step #0: 8aa238cf5652: Verifying Checksum\n",
      "Step #0: 8aa238cf5652: Download complete\n",
      "Step #0: b57d894b9e7f: Download complete\n",
      "Step #0: 1bb0820f7158: Verifying Checksum\n",
      "Step #0: 1bb0820f7158: Download complete\n",
      "Step #0: bd47987755ba: Pull complete\n",
      "Step #0: 29aa6e9dcc22: Verifying Checksum\n",
      "Step #0: 29aa6e9dcc22: Download complete\n",
      "Step #0: 831c222b21d8: Pull complete\n",
      "Step #0: 3c2cba919283: Pull complete\n",
      "Step #0: e378d88a5f59: Pull complete\n",
      "Step #0: df37508d2f5c: Pull complete\n",
      "Step #0: bd5056198be8: Pull complete\n",
      "Step #0: 044a6cc327bc: Pull complete\n",
      "Step #0: c7411e31635f: Pull complete\n",
      "Step #0: 29aa6e9dcc22: Pull complete\n",
      "Step #0: 9777e791df93: Pull complete\n",
      "Step #0: 9adf91901ea3: Pull complete\n",
      "Step #0: 1bb0820f7158: Pull complete\n",
      "Step #0: 8aa238cf5652: Pull complete\n",
      "Step #0: b57d894b9e7f: Pull complete\n",
      "Step #0: Digest: sha256:f5c313fb9dd86c3eaade35265e93d6037cc56f438924a13d32e6633e6cb3cbac\n",
      "Step #0: Status: Downloaded newer image for tensorflow/tfx:0.21.4\n",
      "Step #0:  ---> 8acabd98b4f0\n",
      "Step #0: Step 2/4 : WORKDIR ../pipeline\n",
      "Step #0:  ---> Running in 58dc9bcda8c0\n",
      "Step #0: Removing intermediate container 58dc9bcda8c0\n",
      "Step #0:  ---> 7cd58d6792d5\n",
      "Step #0: Step 3/4 : COPY ./ ./\n",
      "Step #0:  ---> 80c1fea93e05\n",
      "Step #0: Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
      "Step #0:  ---> Running in baa1dad04ff7\n",
      "Step #0: Removing intermediate container baa1dad04ff7\n",
      "Step #0:  ---> 28739d9027a9\n",
      "Step #0: Successfully built 28739d9027a9\n",
      "Step #0: Successfully tagged gcr.io/qwiklabs-gcp-ml-a65a6543b5a6/lab-03-tfx-image:test\n",
      "Finished Step #0\n",
      "Starting Step #1\n",
      "Step #1: Pulling image: gcr.io/qwiklabs-gcp-ml-a65a6543b5a6/tfx-cli\n",
      "Step #1: Using default tag: latest\n",
      "Step #1: latest: Pulling from qwiklabs-gcp-ml-a65a6543b5a6/tfx-cli\n",
      "Step #1: f08d8e2a3ba1: Already exists\n",
      "Step #1: 3baa9cb2483b: Already exists\n",
      "Step #1: 94e5ff4c0b15: Already exists\n",
      "Step #1: 1860925334f9: Already exists\n",
      "Step #1: aa0346bca052: Pulling fs layer\n",
      "Step #1: 2cdc52730f79: Pulling fs layer\n",
      "Step #1: 0ba0de3bfc57: Pulling fs layer\n",
      "Step #1: cfc189ad1b0c: Pulling fs layer\n",
      "Step #1: 1696c6152326: Pulling fs layer\n",
      "Step #1: b326b9dc9e3d: Pulling fs layer\n",
      "Step #1: e48245ee4473: Pulling fs layer\n",
      "Step #1: 4681b4568019: Pulling fs layer\n",
      "Step #1: c3fc7eed71d1: Pulling fs layer\n",
      "Step #1: 3c383b737d47: Pulling fs layer\n",
      "Step #1: 4d58cc5455cb: Pulling fs layer\n",
      "Step #1: 7cc98672bd98: Pulling fs layer\n",
      "Step #1: 8a5f50f1df88: Pulling fs layer\n",
      "Step #1: 3e3ff802ef42: Pulling fs layer\n",
      "Step #1: a1212d691646: Pulling fs layer\n",
      "Step #1: dce1eb79e9cc: Pulling fs layer\n",
      "Step #1: 9242271f737a: Pulling fs layer\n",
      "Step #1: cfc189ad1b0c: Waiting\n",
      "Step #1: 1696c6152326: Waiting\n",
      "Step #1: b326b9dc9e3d: Waiting\n",
      "Step #1: e48245ee4473: Waiting\n",
      "Step #1: 4681b4568019: Waiting\n",
      "Step #1: c3fc7eed71d1: Waiting\n",
      "Step #1: 3c383b737d47: Waiting\n",
      "Step #1: 4d58cc5455cb: Waiting\n",
      "Step #1: 7cc98672bd98: Waiting\n",
      "Step #1: 8a5f50f1df88: Waiting\n",
      "Step #1: 3e3ff802ef42: Waiting\n",
      "Step #1: a1212d691646: Waiting\n",
      "Step #1: dce1eb79e9cc: Waiting\n",
      "Step #1: 9242271f737a: Waiting\n",
      "Step #1: 0ba0de3bfc57: Verifying Checksum\n",
      "Step #1: 0ba0de3bfc57: Download complete\n",
      "Step #1: 2cdc52730f79: Verifying Checksum\n",
      "Step #1: 2cdc52730f79: Download complete\n",
      "Step #1: 1696c6152326: Verifying Checksum\n",
      "Step #1: 1696c6152326: Download complete\n",
      "Step #1: b326b9dc9e3d: Verifying Checksum\n",
      "Step #1: b326b9dc9e3d: Download complete\n",
      "Step #1: cfc189ad1b0c: Verifying Checksum\n",
      "Step #1: cfc189ad1b0c: Download complete\n",
      "Step #1: 4681b4568019: Verifying Checksum\n",
      "Step #1: 4681b4568019: Download complete\n",
      "Step #1: e48245ee4473: Verifying Checksum\n",
      "Step #1: e48245ee4473: Download complete\n",
      "Step #1: c3fc7eed71d1: Verifying Checksum\n",
      "Step #1: c3fc7eed71d1: Download complete\n",
      "Step #1: 3c383b737d47: Verifying Checksum\n",
      "Step #1: 3c383b737d47: Download complete\n",
      "Step #1: 4d58cc5455cb: Verifying Checksum\n",
      "Step #1: 4d58cc5455cb: Download complete\n",
      "Step #1: 7cc98672bd98: Verifying Checksum\n",
      "Step #1: 7cc98672bd98: Download complete\n",
      "Step #1: 3e3ff802ef42: Verifying Checksum\n",
      "Step #1: 3e3ff802ef42: Download complete\n",
      "Step #1: a1212d691646: Verifying Checksum\n",
      "Step #1: a1212d691646: Download complete\n",
      "Step #1: dce1eb79e9cc: Verifying Checksum\n",
      "Step #1: dce1eb79e9cc: Download complete\n",
      "Step #1: aa0346bca052: Verifying Checksum\n",
      "Step #1: aa0346bca052: Download complete\n",
      "Step #1: 9242271f737a: Verifying Checksum\n",
      "Step #1: 9242271f737a: Download complete\n",
      "Step #1: 8a5f50f1df88: Verifying Checksum\n",
      "Step #1: 8a5f50f1df88: Download complete\n",
      "Step #1: aa0346bca052: Pull complete\n",
      "Step #1: 2cdc52730f79: Pull complete\n",
      "Step #1: 0ba0de3bfc57: Pull complete\n",
      "Step #1: cfc189ad1b0c: Pull complete\n",
      "Step #1: 1696c6152326: Pull complete\n",
      "Step #1: b326b9dc9e3d: Pull complete\n",
      "Step #1: e48245ee4473: Pull complete\n",
      "Step #1: 4681b4568019: Pull complete\n",
      "Step #1: c3fc7eed71d1: Pull complete\n",
      "Step #1: 3c383b737d47: Pull complete\n",
      "Step #1: 4d58cc5455cb: Pull complete\n",
      "Step #1: 7cc98672bd98: Pull complete\n",
      "Step #1: 8a5f50f1df88: Pull complete\n",
      "Step #1: 3e3ff802ef42: Pull complete\n",
      "Step #1: a1212d691646: Pull complete\n",
      "Step #1: dce1eb79e9cc: Pull complete\n",
      "Step #1: 9242271f737a: Pull complete\n",
      "Step #1: Digest: sha256:409281b94d73e8e6d5f1ad277d2ee8652d2eb675cba95fc39c3de1c057ad6c9f\n",
      "Step #1: Status: Downloaded newer image for gcr.io/qwiklabs-gcp-ml-a65a6543b5a6/tfx-cli:latest\n",
      "Step #1: gcr.io/qwiklabs-gcp-ml-a65a6543b5a6/tfx-cli:latest\n",
      "Step #1: CLI\n",
      "Step #1: Creating pipeline\n",
      "Step #1: New container image is built. Target image is available in the build spec file.\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit . --config cloudbuild.yaml --substitutions {SUBSTITUTIONS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Setting up GitHub integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you integrate your CI/CD workflow with **GitHub**, using [Cloud Build GitHub App](https://github.com/marketplace/google-cloud-build). \n",
    "You will set up a trigger that starts the CI/CD workflow when a new tag is applied to the **GitHub** repo managing the  pipeline source code. You will use a fork of this repo as your source GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fork of this repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. [Follow the GitHub documentation](https://help.github.com/en/github/getting-started-with-github/fork-a-repo) to fork this repo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.  Create a Cloud Build trigger.**\n",
    "\n",
    "Connect the fork you created in the previous step to your Google Cloud project and create a trigger following the steps in the [Creating GitHub app trigger](https://cloud.google.com/cloud-build/docs/create-github-app-triggers) article. Use the following values on the **Edit trigger** form:\n",
    "\n",
    "|Field|Value|\n",
    "|-----|-----|\n",
    "|Name|[YOUR TRIGGER NAME]|\n",
    "|Description|[YOUR TRIGGER DESCRIPTION]|\n",
    "|Event| Tag|\n",
    "|Source| [YOUR FORK]|\n",
    "|Tag (regex)|.\\*|\n",
    "|Build Configuration|Cloud Build configuration file (yaml or json)|\n",
    "|Cloud Build configuration file location|/ workshops/tfx-caip-tf21/lab-03-tfx-cicd/cloudbuild.yaml|\n",
    "\n",
    "\n",
    "Use the following values for the substitution variables:\n",
    "\n",
    "|Variable|Value|\n",
    "|--------|-----|\n",
    "|_ENDPOINT|[Your inverting proxy host pipeline ENDPOINT]|\n",
    "|_TFX_IMAGE_NAME|lab-03-tfx-image|\n",
    "|_PIPELINE_NAME|tfx_covertype_continuous_training|\n",
    "|_PIPELINE_DSL|runner.py|\n",
    "|_DATA_ROOT_URI|gs://workshop-datasets/covertype/small|\n",
    "|_PIPELINE_FOLDER|workshops/tfx-caip-tf21/lab-03-tfx-cicd/pipeline|\n",
    "|_PYTHON_VERSION|3.7|\n",
    "|_RUNTIME_VERSION|2.1|\n",
    "|_USE_KFP_SA|False|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Trigger the build.**\n",
    "\n",
    "To start an automated build [create a new release of the repo in GitHub](https://help.github.com/en/github/administering-a-repository/creating-releases). Alternatively, you can start the build by applying a tag using `git`. \n",
    "```\n",
    "git tag [TAG NAME]\n",
    "git push origin --tags\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Verify triggered build in Cloud Build dashboard.**\n",
    "\n",
    "After you see the pipeline finish building on the Cloud Build dashboard, return to [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) in the console. Click `OPEN PIPELINES DASHBOARD` and view the newly deployed pipeline. Creating a release tag on GitHub will create a pipeline with the name `tfx_covertype_continuous_training-[TAG NAME]` while doing so from GitHub will create a pipeline with the name `tfx_covertype_continuous_training_github-[TAG NAME]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you walked through authoring a Cloud Build CI/CD workflow that automatically builds and deploys a TFX pipeline. You also integrated your TFX workflow with GitHub by setting up a Cloud Build trigger. In the next lab, you will walk through inspection of TFX metadata and pipeline artifacts created during TFX pipeline runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
