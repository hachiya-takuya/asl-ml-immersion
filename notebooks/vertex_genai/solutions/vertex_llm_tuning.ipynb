{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "# Tuning and deploy a foundation model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "**Learning Objective**\n",
    "\n",
    "1. Learn how to generate a JSONL file for PaLM tuning\n",
    "1. Learn how to launch a tuning job on Vertex Pipeline\n",
    "1. Learn how to query you tuned LLM and evaluate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e",
    "tags": []
   },
   "source": [
    "Creating an LLM requires massive amounts of data, significant computing resources, and specialized skills. In this notebook, you'll learn how tuning allows you to customize a PaLM foundation model on Vertex Generative AI studio for more specific tasks or knowledge domains.\n",
    "\n",
    "While the prompt design is excellent for quick experimentation, if training data is available, you can achieve higher quality by tuning the model. Tuning a model enables you to customize the model response based on examples of the task you want the model to perform.\n",
    "\n",
    "For more details on tuning have a look at the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models).\n",
    "\n",
    "**Quota**: Tuning the `text-bison@001`  model uses the `tpu-v3-8` training resources and the accompanying quotas from your Google Cloud project. Each project has a default quota of eight v3-8 cores, which allows for one to two concurrent tuning jobs. If you want to run more concurrent jobs you need to request additional quota via the [Quotas page](https://console.cloud.google.com/iam-admin/quotas).\n",
    "\n",
    "**Costs:** This tutorial uses billable a component of Google Cloud `Vertex AI Generative AI Studio`.\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "# The version of google-cloud-aiplatform needs to be >= 1.33.0\n",
    "!pip install --upgrade --user \\\n",
    "    google-cloud-aiplatform \\\n",
    "    sequence-evaluate sentence-transformers \\\n",
    "    rouge\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform, bigquery\n",
    "from seq_eval import SeqEval\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vertexai.preview.language_models import TextGenerationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "PROJECT_ID = !(gcloud config get-value project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "BUCKET_NAME = PROJECT_ID\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSRiXkavaalH",
    "outputId": "8b752c8a-d575-4982-85f8-5a40317c8ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dherin-dev/cord19_embeddings.json\n",
      "gs://dherin-dev/salads.csv\n",
      "gs://dherin-dev/tune_data_stack_overflow_python_qa.jsonl\n",
      "gs://dherin-dev/115851500182/\n",
      "gs://dherin-dev/7737964263322419200-616112577574862848/\n",
      "gs://dherin-dev/babyweight/\n",
      "gs://dherin-dev/babyweight_220707_021136/\n",
      "gs://dherin-dev/babyweight_220707_021151/\n",
      "gs://dherin-dev/babyweight_220707_021154/\n",
      "gs://dherin-dev/car_damage_lab_images/\n",
      "gs://dherin-dev/classification-bert-20230411003650/\n",
      "gs://dherin-dev/contextual_bandit_checkpoints/\n",
      "gs://dherin-dev/covertype/\n",
      "gs://dherin-dev/models/\n",
      "gs://dherin-dev/movies/\n",
      "gs://dherin-dev/staging/\n",
      "gs://dherin-dev/taxifare-20230710171207/\n",
      "gs://dherin-dev/taxifare-20230710191151/\n",
      "gs://dherin-dev/taxifare/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $BUCKET_URI || gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdtNETYxaalH"
   },
   "source": [
    "## Tune your Model\n",
    "\n",
    "Now it's time for you to create a tuning job. Tune a foundation model by creating a pipeline job using Generative AI Studio, cURL, or the Python SDK. In this notebook, we will be using the Python SDK. You will be using a Q&A with a context dataset in JSON format.\n",
    "\n",
    "### Training Data\n",
    "ðŸ’¾ Your model tuning dataset must be in a JSONL format where each line contains a single training example. You must make sure that you include instructions.\n",
    "\n",
    "You will use the StackOverflow data on BigQuery Public Datasets, limiting to questions with the `python` tag, and accepted answers for answers since 2020-01-01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Puc3jl8QaalI"
   },
   "source": [
    "First create a helper function to let you easily query BigQuery and return the results as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Eg60aUgvaalI"
   },
   "outputs": [],
   "source": [
    "def run_bq_query(sql):\n",
    "    bq_client = bigquery.Client()\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BydoFfTaalI"
   },
   "source": [
    "Next define the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT CONCAT(q.title, q.body) as input_text, a.body AS output_text\n",
    "FROM\n",
    "    `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "JOIN\n",
    "    `bigquery-public-data.stackoverflow.posts_answers` a\n",
    "ON\n",
    "    q.accepted_answer_id = a.id\n",
    "WHERE\n",
    "    q.accepted_answer_id IS NOT NULL AND\n",
    "    REGEXP_CONTAINS(q.tags, \"python\") AND\n",
    "    a.creation_date >= \"2020-01-01\"\n",
    "LIMIT\n",
    "    1000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "9VTaovLtaalI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: 439a8a5f-91d6-477d-8a6d-4d13d2555b36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>append dataframe in nested loop&lt;p&gt;I have the f...</td>\n",
       "      <td>&lt;p&gt;I am not entirely sure if I understand your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python pandas find element of one column in li...</td>\n",
       "      <td>&lt;p&gt;You can do &lt;code&gt;apply&lt;/code&gt;:&lt;/p&gt;\\n&lt;pre&gt;&lt;c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to add a minimum value constraint in Pyomo...</td>\n",
       "      <td>&lt;p&gt;figured it out. The two methods I described...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Producing Buffer Radius Polygons - Possible Pr...</td>\n",
       "      <td>&lt;p&gt;This is apparently an issue with &lt;code&gt;geov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE for balancing data&lt;p&gt;I am trying to trai...</td>\n",
       "      <td>&lt;p&gt;You haven't given enough of your code or da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  append dataframe in nested loop<p>I have the f...   \n",
       "1  Python pandas find element of one column in li...   \n",
       "2  How to add a minimum value constraint in Pyomo...   \n",
       "3  Producing Buffer Radius Polygons - Possible Pr...   \n",
       "4  SMOTE for balancing data<p>I am trying to trai...   \n",
       "\n",
       "                                         output_text  \n",
       "0  <p>I am not entirely sure if I understand your...  \n",
       "1  <p>You can do <code>apply</code>:</p>\\n<pre><c...  \n",
       "2  <p>figured it out. The two methods I described...  \n",
       "3  <p>This is apparently an issue with <code>geov...  \n",
       "4  <p>You haven't given enough of your code or da...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_bq_query(query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYUg8cBbaalJ"
   },
   "source": [
    "There should be 1000 questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "6FqbVHoeaalJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OftmoPZ6aalJ"
   },
   "source": [
    "Lets split the data into training and evalation. For Extractive Q&A tasks we advise 100+ training examples. In this case you will use 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "aXqBwSwaaalJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "# split is set to 80/20\n",
    "train, evaluation = train_test_split(df, test_size=0.2)\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf-q8TpnaalJ"
   },
   "source": [
    "For tuning, the training data first needs to be converted into a JSONL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filename = \"tune_data_stack_overflow_python_qa.jsonl\"\n",
    "train.to_json(training_data_filename, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "{\"input_text\":\"Assignment operator overloading in python Abstract Syntax Trees<p>I want to overload assignment operator in python on the fly using <a href=\\\"https:\\/\\/docs.python.org\\/3\\/library\\/ast.html\\\" rel=\\\"nofollow noreferrer\\\">Abstract Syntax Trees<\\/a><\\/p>\\n<pre><code>import ast\\nimport astunparse\\n\\nclass OverloadAssignments(ast.NodeTransformer):\\n    def visit_Assign(self, node):\\n        if isinstance(node, ast.Assign) and node.targets:\\n            funcs = node.targets[0]\\n            slot_name_candidate = astunparse.unparse(funcs).strip()\\n            if isinstance(funcs, ast.Name) and &quot;_slot&quot; in slot_name_candidate:\\n                slot_name = ast.Constant(value=slot_name_candidate)\\n                context_variable = ast.Constant(value=astunparse.unparse(node.value).strip())\\n                return ast.Expr([ast.Call(func=ast.Name(id='copy_variable_value', ctx=ast.Load),\\n                                          args=[slot_name, context_variable], keywords=[])])\\n            else:\\n                return node\\n        return node\\n\\nassignment_overloader = OverloadAssignments()\\ncode_chunk = &quot;town_slot=cxt.my_town&quot;\\ntree = ast.parse(code_chunk)\\ntree = assignment_overloader.visit(tree)\\n<\\/code><\\/pre>\\n<p>I use <code>parseprint<\\/code> function for pretty printing code tree structure from here\\n<a href=\\\"https:\\/\\/bitbucket.org\\/takluyver\\/greentreesnakes\\/src\\/master\\/astpp.py\\\" rel=\\\"nofollow noreferrer\\\">https:\\/\\/bitbucket.org\\/takluyver\\/greentreesnakes\\/src\\/master\\/astpp.py<\\/a><\\/p>\\n<p><a href=\\\"http:\\/\\/alexleone.blogspot.co.uk\\/2010\\/01\\/python-ast-pretty-printer.html\\\" rel=\\\"nofollow noreferrer\\\">http:\\/\\/alexleone.blogspot.co.uk\\/2010\\/01\\/python-ast-pretty-printer.html<\\/a><\\/p>\\n<p>which gives me the result<\\/p>\\n<pre><code>parseprint(tree)\\n\\nModule(body=[\\n    Expr(value=[\\n        Call(func=Name(id='copy_variable_value', ctx=&lt;class 'ast.Load'&gt;), args=[\\n            Constant(value='town_slot', kind=None),\\n            Constant(value='cxt.my_town', kind=None),\\n          ], keywords=[]),\\n      ]),\\n  ], type_ignores=[])\\n\\n<\\/code><\\/pre>\\n<p>Than I need to unparse code to string. I do it with another python package:<\\/p>\\n<pre><code>astunparse.unparse(tree)\\n\\nAttributeError: 'Unparser' object has no attribute '_str'\\n<\\/code><\\/pre>\\n<p>which fails.<\\/p>\\n<p>What does cause astunparse to fail in this case?<\\/p>\\n<p>How do I correctly unparse the above code?<\\/p>\\n<p>I expect <code>astunparse<\\/code> to produce the following code chunk:<\\/p>\\n<p><code>copy_variable_value(&quot;town_slot&quot;, &quot;cxt.my_town&quot;)<\\/code><\\/p>\",\"output_text\":\"<p>You do not need to use <code>astunparse<\\/code>, the <code>ast<\\/code> module includes an <code>unparse<\\/code> method:<\\/p>\\n<pre><code>import ast\\nclass AssignOverload(ast.NodeTransformer):\\n   def visit_Assign(self, node):\\n      return ast.Call(func=ast.Name(id='copy_variable_value'), \\n         args=[ast.Constant(value=ast.unparse(i)) for i in [*node.targets, node.value]], \\n         keywords=[])\\n\\ncode_chunk = &quot;town_slot=cxt.my_town&quot;\\na = AssignOverload()\\nresult = a.visit(ast.parse(code_chunk))\\nprint(ast.unparse(result))\\n<\\/code><\\/pre>\\n<p>Output:<\\/p>\\n<pre><code>copy_variable_value('town_slot', 'cxt.my_town')\\n<\\/code><\\/pre>\"}\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 $training_data_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FV8Wxz7JaalN"
   },
   "source": [
    "You can then export the local file to GCS, so that it can be used by Vertex AI for the tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "vDDLHac5aalN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Copying file://tune_data_stack_overflow_python_qa.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
      "Operation completed over 1 objects/2.3 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $training_data_filename $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff68wmzoaalN"
   },
   "source": [
    "You can check to make sure that the file successfully transferred to your Google Cloud Storage bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "2-DnKpYlaalN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "   2410384  2023-09-20T00:36:52Z  gs://dherin-dev/tune_data_stack_overflow_python_qa.jsonl#1695170212151253  metageneration=1\n",
      "TOTAL: 1 objects, 2410384 bytes (2.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA_URI = f\"{BUCKET_URI}/{training_data_filename}\"\n",
    "!gsutil ls -al $TRAINING_DATA_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mW7K57BaalN",
    "tags": []
   },
   "source": [
    "### Model Tuning\n",
    "Now it's time to start to tune a model. You will use the Vertex AI SDK to submit our tuning job.\n",
    "\n",
    "#### Recommended Tuning Configurations\n",
    "âœ… Here are some recommended configurations for tuning a foundation model based on the task, in this example Q&A. You can find more in the [documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models).\n",
    "\n",
    "Extractive QA:\n",
    "- Make sure that your train dataset size is 100+\n",
    "- Training steps [100-500]. You can try more than one value to get the best performance on a particular dataset (e.g. 100, 200, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0XNL9ojaalN"
   },
   "source": [
    "Next it's time to start your tuning job. \n",
    "\n",
    "**Disclaimer:** tuning and deploying a model takes time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "on4baTh5aalN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: asl-palm-text-tuned-model-1695170250.4494693\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/115851500182/locations/europe-west4/pipelineJobs/tune-large-model-20230920003730\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/115851500182/locations/europe-west4/pipelineJobs/tune-large-model-20230920003730')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west4/pipelines/runs/tune-large-model-20230920003730?project=115851500182\n",
      "PipelineJob projects/115851500182/locations/europe-west4/pipelineJobs/tune-large-model-20230920003730 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/115851500182/locations/europe-west4/pipelineJobs/tune-large-model-20230920003730 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/115851500182/locations/europe-west4/pipelineJobs/tune-large-model-20230920003730 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/115851500182/locations/europe-west4/pipelineJobs/tune-large-model-20230920003730 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/115851500182/locations/europe-west4/pipelineJobs/tune-large-model-20230920003730 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/115851500182/locations/europe-west4/pipelineJobs/tune-large-model-20230920003730 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS = 500\n",
    "MODEL_NAME = f\"asl-palm-text-tuned-model-{time.time()}\"\n",
    "print(\"Model name:\", MODEL_NAME)\n",
    "\n",
    "model.tune_model(\n",
    "    training_data=TRAINING_DATA_URI,\n",
    "    model_display_name=MODEL_NAME,\n",
    "    train_steps=TRAIN_STEPS,\n",
    "    # Tuning can only happen in the \"europe-west4\" location\n",
    "    tuning_job_location=\"europe-west4\",\n",
    "    # Model can only be deployed in the \"us-central1\" location\n",
    "    tuned_model_location=\"us-central1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6JC8XplaalO"
   },
   "source": [
    "## Retrieve the foundational model from Vertex AI Model registry\n",
    "\n",
    "When your tuning job is finished, your model will be available on Vertex AI Model Registry. The following Python SDK sample shows you how to list tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['projects/115851500182/locations/us-central1/models/7558911543518167040']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "model.list_tuned_model_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZriyF0V-aalO"
   },
   "source": [
    "You can also use the Google Cloud Console UI to view all of your model in [Vertex AI Model Registry](https://console.cloud.google.com/vertex-ai/models?). Below you can see an example of a tuned foundational model available on Vertex AI Model Registry.\n",
    "\n",
    "Now it's time to get predictions. First you need to get the latest tuned model from the Vertex AI Model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "j66dr12taalO"
   },
   "outputs": [],
   "source": [
    "deployed_model = TextGenerationModel.get_tuned_model(\n",
    "    model.list_tuned_model_names()[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDOueoptaalO"
   },
   "source": [
    "Now you can start send a prompt to the API. Feel free to update the following prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2ERbfPJPaalO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import tensorflow as tf\n",
      "\n",
      "# Create a GCS bucket\n",
      "bucket = tf.gfile.GFile('gs://my-bucket/', 'w')\n",
      "\n",
      "# Create a checkpoint directory\n",
      "checkpoint_dir = 'gs://my-bucket/checkpoints/'\n",
      "\n",
      "# Create a checkpoint file\n",
      "checkpoint_file = os.path.join(checkpoint_dir, 'checkpoint')\n",
      "\n",
      "# Create a saver\n",
      "saver = tf.train.Saver()\n",
      "\n",
      "# Save the checkpoint\n",
      "saver.save(sess, checkpoint_file)\n",
      "\n",
      "# Restore the\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "How can I store my TensorFlow checkpoint on Google Cloud Storage?\n",
    "\n",
    "Python example:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(deployed_model.predict(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will generate the evaluation metrics. `evaluator.evaluate` will return a few eval metrics. Some of the important ones are:\n",
    "- [Blue](https://en.wikipedia.org/wiki/BLEU): The BLEU evaluation metric is a measure of the similarity between a machine-generated text and a human-written reference text.\n",
    "- [Rouge](https://en.wikipedia.org/wiki/ROUGE_(metric)): The ROUGE evaluation metric is a measure of the overlap between a machine-generated text and a human-written reference text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtYr_KNPaalO",
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "It's essential to evaluate your model to understand its performance. Evaluation can be done in an automated way using evaluation metrics like F1 or Rouge. You can also leverage human evaluation methods. Human evaluation methods involve asking humans to rate the quality of the LLM's answers. This can be done through crowdsourcing or by having experts evaluate the responses. Some standard human evaluation metrics include fluency, coherence, relevance, and informativeness. Often you want to choose a mix of evaluation metrics to get a good understanding of your model performance. Below you will find an example of how you can do the evaluation.\n",
    "\n",
    "In this example you will be using [sequence-evaluate](https://pypi.org/project/sequence-evaluate/) to evaluation the tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS10ybdraalO"
   },
   "source": [
    "Earlier in the notebook, you created a train and eval dataset. Now it's time to take some of the eval data. You will use the questions to get a response from our tuned model, and the answers we will use as a reference:\n",
    "\n",
    "- **Candidates**: Answers generated by the tuned model.\n",
    "- **References**: Original answers that we will use to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "LKMmIH0XaalO"
   },
   "outputs": [],
   "source": [
    "# you can change the number of rows you want to use\n",
    "EVAL_ROWS = 60\n",
    "\n",
    "evaluation = evaluation.head(EVAL_ROWS)\n",
    "evaluation_question = evaluation.input_text\n",
    "evaluation_answer = evaluation.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_input, eval_output):\n",
    "    candidates = []\n",
    "\n",
    "    for i in eval_input:\n",
    "        response = model.predict(i)\n",
    "        candidates.append(response.text)\n",
    "    references = eval_output.tolist()\n",
    "\n",
    "    evaluator = SeqEval()\n",
    "    return evaluator.evaluate(candidates, references, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the tunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu_1': 0.04047520756830512,\n",
       " 'bleu_2': 0.015100714783626129,\n",
       " 'bleu_3': 0.008332257944719989,\n",
       " 'bleu_4': 0.004868503649911386,\n",
       " 'rouge_1_precision': 0.2226664727278332,\n",
       " 'rouge_1_recall': 0.08248341451392938,\n",
       " 'rouge_1_f1': 0.11105924745988842,\n",
       " 'rouge_2_precision': 0.02592229901067698,\n",
       " 'rouge_2_recall': 0.01139208073925231,\n",
       " 'rouge_2_f1': 0.01428915384614036,\n",
       " 'rouge_l_precision': 0.20558055140278145,\n",
       " 'rouge_l_recall': 0.07492196202502902,\n",
       " 'rouge_l_f1': 0.10178188164640203,\n",
       " 'inter_dist1': 0.02047382269530938,\n",
       " 'inter_dist2': 0.1481372832263503,\n",
       " 'intra_dist1': 0.11618918174622357,\n",
       " 'intra_dist2': 0.4187750753268838,\n",
       " 'semantic_textual_similarity': 0.4033529758453369}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(deployed_model, evaluation_question, evaluation_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also compare it to the untuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu_1': 0.1003128560268671,\n",
       " 'bleu_2': 0.05564918804413014,\n",
       " 'bleu_3': 0.04236881534645315,\n",
       " 'bleu_4': 0.034599527052774505,\n",
       " 'rouge_1_precision': 0.267516380123697,\n",
       " 'rouge_1_recall': 0.1558227088368697,\n",
       " 'rouge_1_f1': 0.17846678760532284,\n",
       " 'rouge_2_precision': 0.07045565520237056,\n",
       " 'rouge_2_recall': 0.04442757694288905,\n",
       " 'rouge_2_f1': 0.04805766823189456,\n",
       " 'rouge_l_precision': 0.2548800164873334,\n",
       " 'rouge_l_recall': 0.14979437731505252,\n",
       " 'rouge_l_f1': 0.17098167425295888,\n",
       " 'inter_dist1': 0.016247833586984978,\n",
       " 'inter_dist2': 0.12961354726527693,\n",
       " 'intra_dist1': 0.09521129488653601,\n",
       " 'intra_dist2': 0.3913011373479328,\n",
       " 'semantic_textual_similarity': 0.5161213874816895}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, evaluation_question, evaluation_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the score for the tunned model are lower than the original foundation model, you'll need to increase the size the of tuning set, and possibly modify the number of steps you are using for tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgement \n",
    "\n",
    "This notebook is adapted from a [tutorial](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/tuning/getting_started_tuning.ipynb)\n",
    "written by Polong Lin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "source": [
    "Copyright 2023 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
