{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2ccd92-c76c-4e17-8ec7-da72ca6bb709",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Vertex AI GenAI Evaluation Service\n",
    "\n",
    "Vertex AI's Gen AI evaluation service empowers you to assess any generative AI model or application according to your specific requirements.\n",
    "\n",
    "Instead of relying solely on general leaderboards and reports, you can define your own evaluation criteria and directly compare how different models perform against your unique needs, use case and data.\n",
    "\n",
    "This service allows you to:\n",
    "\n",
    "- Gain a deeper understanding of model performance. And, Go beyond general metrics and understand how a model handles your specific data and tasks.\n",
    "- Make informed decisions throughout the development lifecycle. By using evaluations to guide model selection, refine prompt engineering, and optimize model customization.\n",
    "- Streamline your evaluation workflow by leveraging Vertex AI's integrated tools to easily launch and reuse evaluations as needed.\n",
    "\n",
    "Essentially, it puts you in control of evaluating generative AI, ensuring the models you choose are the best fit for your specific applications.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will learn:\n",
    "\n",
    "- How to use Vertex AI Gen AI Evaluation Service \n",
    "- Different types of evaluation techniques (Computation Based and Model Based)\n",
    "- How to prepare you dataset and get it ready for evaluation\n",
    "- Analyze and understand the results from evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f0365-f681-487d-9f93-35c6bfe2e6d6",
   "metadata": {},
   "source": [
    "### Setup\n",
    "This notebook uses a specific kernel to include needed dependencies. Run the cell below to create it and then select `gemini_kernel` in the top right before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce5115-8178-418c-a979-67386b6889e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd ~/asl-ml-immersion && make gemini_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884d3670-b507-4c9d-b70b-df13f937a94d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Main\n",
    "from vertexai.evaluation import (\n",
    "    EvalTask,\n",
    "    MetricPromptTemplateExamples,\n",
    "    PairwiseMetric,\n",
    "    PointwiseMetric,\n",
    "    PointwiseMetricPromptTemplate,\n",
    ")\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da785841-5902-4960-b421-f47892be68f5",
   "metadata": {},
   "source": [
    "### Helper Function\n",
    "\n",
    "The function helps us display the results from the evaluation SDK in a readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b01eb7-2e08-45df-ac52-3cab2cc8f262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_eval_report(eval_result, metrics=None):\n",
    "    \"\"\"Display the evaluation results.\"\"\"\n",
    "\n",
    "    title, summary_metrics, report_df = eval_result\n",
    "    metrics_df = pd.DataFrame.from_dict(summary_metrics, orient=\"index\").T\n",
    "    if metrics:\n",
    "        metrics_df = metrics_df.filter(\n",
    "            [\n",
    "                metric\n",
    "                for metric in metrics_df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "        report_df = report_df.filter(\n",
    "            [\n",
    "                metric\n",
    "                for metric in report_df.columns\n",
    "                if any(selected_metric in metric for selected_metric in metrics)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Display the title with Markdown for emphasis\n",
    "    display(Markdown(f\"## {title}\"))\n",
    "\n",
    "    # Display the metrics DataFrame\n",
    "    display(Markdown(\"### Summary Metrics\"))\n",
    "    display(metrics_df)\n",
    "\n",
    "    # Display the detailed report DataFrame\n",
    "    display(Markdown(\"### Report Metrics\"))\n",
    "    display(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3eae9-0a4e-471a-9319-7169c6825138",
   "metadata": {},
   "source": [
    "## Evaluation Process\n",
    "\n",
    "Vertex AI's Gen AI evaluation service lets you assess any generative model based on your specific needs and criteria.\n",
    "\n",
    "These are the four steps you will follow to help you evaluate:\n",
    "\n",
    "1. Define: Tailor metrics to your business goals and choose your evaluation approach (Computation based vs Model Based).\n",
    "2. Prepare: Create a dataset that reflects your real-world use case.\n",
    "3. Run: Easily launch evaluations using templates or existing examples. Define your models and create reusable `EvalTasks` within Vertex AI to use in other evaluations.\n",
    "4. Analyze: Interpret your results and understand how each model performs against your specific criteria.\n",
    "\n",
    "Let's take a look at these steps one by one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2012a826-4c47-4272-85f4-74225b86018d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Computation Based Metrics\n",
    "\n",
    "[Computation based metrics](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#computation-based-metrics) are computed using mathematical formulas to compare the model's output against a **ground truth or reference**. Commonly used computation-based metrics include ROUGE and BLEU. The commonly used metrics can be categorized into the following groups:\n",
    "\n",
    "- Lexicon-based metrics: Use math to calculate the string similarities between LLM-generated results and ground truth, such as `Exact Match` and `ROUGE`.\n",
    "- Count-based metrics: Aggregate the number of rows that hit or miss certain ground-truth labels, such as `F1-score`, `Accuracy`, and `Tool Name Match`.\n",
    "- Embedding-based metrics: Calculate the distance between the LLM-generated results and ground truth in the embedding space, reflecting their level of similarity. These include `cosine similarity` and `euclidean distance` \n",
    "\n",
    "Let's say that we are trying to evaluate how well different prompts works for summarization using Gemini. We'll start by defining a few articles in `context` and since we are using computation based metrics for evaluation, we will also need to define the ground truth for the summaries. This will be defined in `reference`. `eval_dataset` should be a dataframe that contains columns needed for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0593398-94d2-4a74-98c3-4a16e3f0fb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"Summarize the following article\"\n",
    "\n",
    "context = [\n",
    "    \"To make a classic spaghetti carbonara, start by bringing a large pot of salted water to a boil. While the water is heating up, cook pancetta or guanciale in a skillet with olive oil over medium heat until it's crispy and golden brown. Once the pancetta is done, remove it from the skillet and set it aside. In the same skillet, whisk together eggs, grated Parmesan cheese, and black pepper to make the sauce. When the pasta is cooked al dente, drain it and immediately toss it in the skillet with the egg mixture, adding a splash of the pasta cooking water to create a creamy sauce.\",\n",
    "    \"Preparing a perfect risotto requires patience and attention to detail. Begin by heating butter in a large, heavy-bottomed pot over medium heat. Add finely chopped onions and minced garlic to the pot, and cook until they're soft and translucent, about 5 minutes. Next, add Arborio rice to the pot and cook, stirring constantly, until the grains are coated with the butter and begin to toast slightly. Pour in a splash of white wine and cook until it's absorbed. From there, gradually add hot chicken or vegetable broth to the rice, stirring frequently, until the risotto is creamy and the rice is tender with a slight bite.\",\n",
    "    \"To bake a decadent chocolate cake from scratch, start by preheating your oven to 350°F (175°C) and greasing and flouring two 9-inch round cake pans. In a large mixing bowl, cream together softened butter and granulated sugar until light and fluffy. Beat in eggs one at a time, making sure each egg is fully incorporated before adding the next. In a separate bowl, sift together all-purpose flour, cocoa powder, baking powder, baking soda, and salt. Divide the batter evenly between the prepared cake pans and bake for 25-30 minutes, or until a toothpick inserted into the center comes out clean.\",\n",
    "]\n",
    "\n",
    "reference = [\n",
    "    \"The process of making spaghetti carbonara involves boiling pasta, crisping pancetta or guanciale, whisking together eggs and Parmesan cheese, and tossing everything together to create a creamy sauce.\",\n",
    "    \"Preparing risotto entails sautéing onions and garlic, toasting Arborio rice, adding wine and broth gradually, and stirring until creamy and tender.\",\n",
    "    \"Baking a decadent chocolate cake requires creaming butter and sugar, beating in eggs and alternating dry ingredients with buttermilk before baking until done.\",\n",
    "]\n",
    "\n",
    "eval_dataset = pd.DataFrame(\n",
    "    {\n",
    "        \"context\": context,\n",
    "        \"reference\": reference,\n",
    "        \"instruction\": [instruction] * len(context),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f1ddc-a3b6-4b12-a839-bf4b658e65c5",
   "metadata": {},
   "source": [
    "Now, we'll define different prompt templates to evaluate. This list can include all the different prompt templates you want to experiment with. For the purpose of demostration, we'll use two different prompt templates below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8649578-1f9d-44ea-a40f-bcc3aab2d9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_templates = [\n",
    "    \"Instruction: {instruction}. Article: {context}. Summary:\",\n",
    "    \"Article: {context}. Complete this task: {instruction}, in one sentence. Summary:\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425b0d3-7cae-43f3-b51b-011f32496840",
   "metadata": {},
   "source": [
    "Next, we will define the different metrics we want to measure for this task. There are different metrics that are defined by Vertex AI based on the task. You can take a look at the [documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval#computation-based-metrics) to see the different metrics. And, take a look at the [API documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/reference/python/latest/vertexai.preview.evaluation.EvalTask#vertexai_preview_evaluation_EvalTask) to refer to the right string values for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed1fc16-be95-4e98-b623-0193a374b7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"rouge_1\",\n",
    "    \"rouge_l_sum\",\n",
    "    \"bleu\",\n",
    "    \"safety\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b524bce-a5ec-4237-8d6e-388087ac4583",
   "metadata": {},
   "source": [
    "We'll configure the model that we are going to use for the generating the reponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04822606-ebf8-4138-97d6-3f8886a8d4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"temperature\": 0.3,\n",
    "}\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "gemini_model = GenerativeModel(\n",
    "    \"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b66a31-ef55-49cc-a119-eb180761a92d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, that we have configured all the parameters, we are ready to start evaluating. We will use [EvalTask](https://cloud.google.com/vertex-ai/generative-ai/docs/reference/python/latest/vertexai.preview.evaluation.EvalTask) to kick of a Vertex AI Experiment for our evaluation. \n",
    "\n",
    "#### Understand the EvalTask class\n",
    "\n",
    "The EvalTask class is a core component of the Gen AI Evaluation Service SDK framework. It allows you to define and run evaluation jobs against your Gen AI models/applications, providing a structured way to measure their performance on specific tasks. Think of an EvalTask as a blueprint for your evaluation process. Evaluation tasks must contain an evaluation dataset, and a list of metrics to evaluate. Supported metrics are documented on the Generative AI on Vertex AI [Define your evaluation metrics page](https://cloud.google.com/vertex-ai/generative-ai/docs/models/determine-eval). The dataset can be an `pandas.DataFrame`, Python dictionary or a file path URI and can contain default column names such as `prompt`, `reference`, `response`, and `baseline_model_response`.  \n",
    "\n",
    "- Bring-your-own-response (BYOR): You already have the data that you want to evaluate stored in the dataset. You can customize the response column names for both your model and the baseline model using parameters like response_column_name and baseline_model_response_column_name or through the metric_column_mapping.\n",
    "\n",
    "- Perform model inference without a prompt template: You have a dataset containing the input prompts to the model and want to perform model inference before evaluation. A column named prompt is required in the evaluation dataset and is used directly as input to the model.\n",
    "\n",
    "- Perform model inference with a prompt template: You have a dataset containing the input variables to the prompt template and want to assemble the prompts for model inference. Evaluation dataset must contain column names corresponding to the variable names in the prompt template. For example, if prompt template is \"Instruction: {instruction}, context: {context}\", the dataset must contain instruction and context columns.\n",
    "\n",
    "EvalTask supports extensive evaluation scenarios including BYOR, model inference with Gemini models, 3P models endpoints/SDK clients, or custom model generation functions, using computation-based metrics, model-based pointwise and pairwise metrics. The evaluate() method triggers the evaluation process, optionally taking a model, prompt template, experiment logging configuartions, and other evaluation run configurations. You can view the SDK reference documentation for [Gen AI Evaluation](https://cloud.google.com/vertex-ai/generative-ai/docs/reference/python/latest/vertexai.evaluation) package for more details.\n",
    "\n",
    "To start with, we'll be using model inference with prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3251b65-f688-4e4b-80d8-bd439f34c2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"prompt-engineering-eval\"\n",
    "\n",
    "summarization_eval_task = EvalTask(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=metrics,\n",
    "    experiment=experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae71ec62-81a3-4044-af49-3c35e8618889",
   "metadata": {},
   "source": [
    "Please note: The cell below takes 10-15 mins to finish executing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bfde61a-20a8-4e54-a5c7-94ca0a743766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-3423e65b-01c3-40b4-aa7f-f0d8811ef828\" href=\"#view-view-vertex-resource-3423e65b-01c3-40b4-aa7f-f0d8811ef828\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-3423e65b-01c3-40b4-aa7f-f0d8811ef828');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/prompt-engineering-eval/runs?project=sanjana-sandbox-012024');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/prompt-engineering-eval/runs?project=sanjana-sandbox-012024', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/27138301346/locations/us-central1/metadataStores/default/contexts/prompt-engineering-eval-eval-prompt-engineering-cisduk8n-prompt-0 to Experiment: prompt-engineering-eval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-626250b5-126d-4f4c-a31f-d60cd40258e2\" href=\"#view-view-vertex-resource-626250b5-126d-4f4c-a31f-d60cd40258e2\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-626250b5-126d-4f4c-a31f-d60cd40258e2');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/prompt-engineering-eval/runs/prompt-engineering-eval-eval-prompt-engineering-cisduk8n-prompt-0?project=sanjana-sandbox-012024');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/prompt-engineering-eval/runs/prompt-engineering-eval-eval-prompt-engineering-cisduk8n-prompt-0?project=sanjana-sandbox-012024', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Eval Experiment metadata: {'prompt_template': 'Instruction: {instruction}. Article: {context}. Summary:', 'model_name': 'publishers/google/models/gemini-1.5-pro', 'temperature': 0.3, 'HARM_CATEGORY_UNSPECIFIED': 'BLOCK_NONE', 'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE', 'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE', 'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE', 'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE'}\n",
      "Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
      "Generating a total of 3 responses from Gemini model gemini-1.5-pro.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 responses are successfully generated from Gemini model gemini-1.5-pro.\n",
      "Multithreaded Batch Inference took: 1.8594790310016833 seconds.\n",
      "Computing metrics with a total of 12 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 12/12 [00:45<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 12 metric requests are successfully computed.\n",
      "Evaluation Took:45.81832159901387 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-055c95f2-41c5-421a-ae53-59545c478230\" href=\"#view-view-vertex-resource-055c95f2-41c5-421a-ae53-59545c478230\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-055c95f2-41c5-421a-ae53-59545c478230');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/prompt-engineering-eval/runs?project=sanjana-sandbox-012024');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/prompt-engineering-eval/runs?project=sanjana-sandbox-012024', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/27138301346/locations/us-central1/metadataStores/default/contexts/prompt-engineering-eval-eval-prompt-engineering-cisduk8n-prompt-1 to Experiment: prompt-engineering-eval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-5d6a90c1-eb64-49b2-afc6-7d99f8397e8f\" href=\"#view-view-vertex-resource-5d6a90c1-eb64-49b2-afc6-7d99f8397e8f\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-5d6a90c1-eb64-49b2-afc6-7d99f8397e8f');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/prompt-engineering-eval/runs/prompt-engineering-eval-eval-prompt-engineering-cisduk8n-prompt-1?project=sanjana-sandbox-012024');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/prompt-engineering-eval/runs/prompt-engineering-eval-eval-prompt-engineering-cisduk8n-prompt-1?project=sanjana-sandbox-012024', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Eval Experiment metadata: {'prompt_template': 'Article: {context}. Complete this task: {instruction}, in one sentence. Summary:', 'model_name': 'publishers/google/models/gemini-1.5-pro', 'temperature': 0.3, 'HARM_CATEGORY_UNSPECIFIED': 'BLOCK_NONE', 'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE', 'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE', 'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE', 'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE'}\n",
      "Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
      "Generating a total of 3 responses from Gemini model gemini-1.5-pro.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 responses are successfully generated from Gemini model gemini-1.5-pro.\n",
      "Multithreaded Batch Inference took: 1.3533338909910526 seconds.\n",
      "Computing metrics with a total of 12 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 12/12 [00:45<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 12 metric requests are successfully computed.\n",
      "Evaluation Took:45.88354647200322 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_uuid(length: int = 8) -> str:\n",
    "    \"\"\"Generate a uuid of a specified length (default=8).\"\"\"\n",
    "    return \"\".join(\n",
    "        random.choices(string.ascii_lowercase + string.digits, k=length)\n",
    "    )\n",
    "\n",
    "\n",
    "run_id = generate_uuid()\n",
    "eval_results = []\n",
    "\n",
    "\n",
    "for i, prompt_template in enumerate(prompt_templates):\n",
    "    experiment_run_name = f\"eval-prompt-engineering-{run_id}-prompt-{i}\"\n",
    "\n",
    "    eval_result = summarization_eval_task.evaluate(\n",
    "        prompt_template=prompt_template,\n",
    "        experiment_run_name=experiment_run_name,\n",
    "        model=gemini_model,\n",
    "    )\n",
    "\n",
    "    eval_results.append(\n",
    "        (f\"Prompt #{i}\", eval_result.summary_metrics, eval_result.metrics_table)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45433208-2c55-4956-9b08-7340d499d1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt #0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Summary Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>rouge_1/mean</th>\n",
       "      <th>rouge_1/std</th>\n",
       "      <th>rouge_l_sum/mean</th>\n",
       "      <th>rouge_l_sum/std</th>\n",
       "      <th>bleu/mean</th>\n",
       "      <th>bleu/std</th>\n",
       "      <th>safety/mean</th>\n",
       "      <th>safety/std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.426527</td>\n",
       "      <td>0.089806</td>\n",
       "      <td>0.318022</td>\n",
       "      <td>0.038028</td>\n",
       "      <td>0.088898</td>\n",
       "      <td>0.04816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_count  rouge_1/mean  rouge_1/std  rouge_l_sum/mean  rouge_l_sum/std  \\\n",
       "0        3.0      0.426527     0.089806          0.318022         0.038028   \n",
       "\n",
       "   bleu/mean  bleu/std  safety/mean  safety/std  \n",
       "0   0.088898   0.04816          1.0         0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Report Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference</th>\n",
       "      <th>instruction</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>rouge_1/score</th>\n",
       "      <th>rouge_l_sum/score</th>\n",
       "      <th>bleu/score</th>\n",
       "      <th>safety/explanation</th>\n",
       "      <th>safety/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To make a classic spaghetti carbonara, start b...</td>\n",
       "      <td>The process of making spaghetti carbonara invo...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>Instruction: Summarize the following article. ...</td>\n",
       "      <td>This article provides a concise guide to makin...</td>\n",
       "      <td>0.506024</td>\n",
       "      <td>0.289157</td>\n",
       "      <td>0.140997</td>\n",
       "      <td>The response provides a safe summary of instru...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preparing a perfect risotto requires patience ...</td>\n",
       "      <td>Preparing risotto entails sautéing onions and ...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>Instruction: Summarize the following article. ...</td>\n",
       "      <td>Making perfect risotto takes patience and prec...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.046005</td>\n",
       "      <td>The response is safe, containing no harmful or...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To bake a decadent chocolate cake from scratch...</td>\n",
       "      <td>Baking a decadent chocolate cake requires crea...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>Instruction: Summarize the following article. ...</td>\n",
       "      <td>This article provides a concise recipe for a c...</td>\n",
       "      <td>0.329114</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>The response is safe, as it provides a summary...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  To make a classic spaghetti carbonara, start b...   \n",
       "1  Preparing a perfect risotto requires patience ...   \n",
       "2  To bake a decadent chocolate cake from scratch...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The process of making spaghetti carbonara invo...   \n",
       "1  Preparing risotto entails sautéing onions and ...   \n",
       "2  Baking a decadent chocolate cake requires crea...   \n",
       "\n",
       "                       instruction  \\\n",
       "0  Summarize the following article   \n",
       "1  Summarize the following article   \n",
       "2  Summarize the following article   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Instruction: Summarize the following article. ...   \n",
       "1  Instruction: Summarize the following article. ...   \n",
       "2  Instruction: Summarize the following article. ...   \n",
       "\n",
       "                                            response  rouge_1/score  \\\n",
       "0  This article provides a concise guide to makin...       0.506024   \n",
       "1  Making perfect risotto takes patience and prec...       0.444444   \n",
       "2  This article provides a concise recipe for a c...       0.329114   \n",
       "\n",
       "   rouge_l_sum/score  bleu/score  \\\n",
       "0           0.289157    0.140997   \n",
       "1           0.361111    0.046005   \n",
       "2           0.303797    0.079692   \n",
       "\n",
       "                                  safety/explanation  safety/score  \n",
       "0  The response provides a safe summary of instru...           1.0  \n",
       "1  The response is safe, containing no harmful or...           1.0  \n",
       "2  The response is safe, as it provides a summary...           1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Prompt #1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Summary Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>rouge_1/mean</th>\n",
       "      <th>rouge_1/std</th>\n",
       "      <th>rouge_l_sum/mean</th>\n",
       "      <th>rouge_l_sum/std</th>\n",
       "      <th>bleu/mean</th>\n",
       "      <th>bleu/std</th>\n",
       "      <th>safety/mean</th>\n",
       "      <th>safety/std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.415214</td>\n",
       "      <td>0.117342</td>\n",
       "      <td>0.27256</td>\n",
       "      <td>0.038558</td>\n",
       "      <td>0.076811</td>\n",
       "      <td>0.058328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_count  rouge_1/mean  rouge_1/std  rouge_l_sum/mean  rouge_l_sum/std  \\\n",
       "0        3.0      0.415214     0.117342           0.27256         0.038558   \n",
       "\n",
       "   bleu/mean  bleu/std  safety/mean  safety/std  \n",
       "0   0.076811  0.058328          1.0         0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Report Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference</th>\n",
       "      <th>instruction</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>rouge_1/score</th>\n",
       "      <th>rouge_l_sum/score</th>\n",
       "      <th>bleu/score</th>\n",
       "      <th>safety/explanation</th>\n",
       "      <th>safety/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To make a classic spaghetti carbonara, start b...</td>\n",
       "      <td>The process of making spaghetti carbonara invo...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>Article: To make a classic spaghetti carbonara...</td>\n",
       "      <td>Summary: Classic spaghetti carbonara is made b...</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.144007</td>\n",
       "      <td>The response is safe, as it does not contain a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preparing a perfect risotto requires patience ...</td>\n",
       "      <td>Preparing risotto entails sautéing onions and ...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>Article: Preparing a perfect risotto requires ...</td>\n",
       "      <td>Summary: Making perfect risotto involves slowl...</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.047172</td>\n",
       "      <td>The response is safe, as it contains none of t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To bake a decadent chocolate cake from scratch...</td>\n",
       "      <td>Baking a decadent chocolate cake requires crea...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>Article: To bake a decadent chocolate cake fro...</td>\n",
       "      <td>Summary: This article provides a concise recip...</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.039253</td>\n",
       "      <td>The response is safe. It provides a one-senten...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  To make a classic spaghetti carbonara, start b...   \n",
       "1  Preparing a perfect risotto requires patience ...   \n",
       "2  To bake a decadent chocolate cake from scratch...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The process of making spaghetti carbonara invo...   \n",
       "1  Preparing risotto entails sautéing onions and ...   \n",
       "2  Baking a decadent chocolate cake requires crea...   \n",
       "\n",
       "                       instruction  \\\n",
       "0  Summarize the following article   \n",
       "1  Summarize the following article   \n",
       "2  Summarize the following article   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Article: To make a classic spaghetti carbonara...   \n",
       "1  Article: Preparing a perfect risotto requires ...   \n",
       "2  Article: To bake a decadent chocolate cake fro...   \n",
       "\n",
       "                                            response  rouge_1/score  \\\n",
       "0  Summary: Classic spaghetti carbonara is made b...       0.542373   \n",
       "1  Summary: Making perfect risotto involves slowl...       0.392157   \n",
       "2  Summary: This article provides a concise recip...       0.311111   \n",
       "\n",
       "   rouge_l_sum/score  bleu/score  \\\n",
       "0           0.237288    0.144007   \n",
       "1           0.313725    0.047172   \n",
       "2           0.266667    0.039253   \n",
       "\n",
       "                                  safety/explanation  safety/score  \n",
       "0  The response is safe, as it does not contain a...           1.0  \n",
       "1  The response is safe, as it contains none of t...           1.0  \n",
       "2  The response is safe. It provides a one-senten...           1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for eval_result in eval_results:\n",
    "    display_eval_report(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5bace3-17f2-47e8-9644-64b86e8da73a",
   "metadata": {},
   "source": [
    "You can view the results from the experiment runs using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06eda606-abcd-4a64-801f-f3fcf0e9b126",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.HARM_CATEGORY_UNSPECIFIED</th>\n",
       "      <th>param.model_name</th>\n",
       "      <th>param.HARM_CATEGORY_DANGEROUS_CONTENT</th>\n",
       "      <th>param.temperature</th>\n",
       "      <th>param.HARM_CATEGORY_SEXUALLY_EXPLICIT</th>\n",
       "      <th>param.HARM_CATEGORY_HARASSMENT</th>\n",
       "      <th>...</th>\n",
       "      <th>metric.fluency/mean</th>\n",
       "      <th>metric.coherence/mean</th>\n",
       "      <th>metric.summarization_quality/mean</th>\n",
       "      <th>metric.verbosity/std</th>\n",
       "      <th>metric.groundedness/mean</th>\n",
       "      <th>metric.groundedness/std</th>\n",
       "      <th>metric.verbosity/mean</th>\n",
       "      <th>metric.summarization_quality/std</th>\n",
       "      <th>metric.fluency/std</th>\n",
       "      <th>metric.coherence/std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-cisduk8n-prompt-1</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-cisduk8n-prompt-0</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-bqvcqujy-prompt-1</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-bqvcqujy-prompt-0</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-xo3pmfsw-prompt-2</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-xo3pmfsw-prompt-1</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-xo3pmfsw-prompt-0</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-7laouxyz-prompt-2</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-7laouxyz-prompt-1</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.121320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prompt-engineering-eval</td>\n",
       "      <td>eval-prompt-engineering-7laouxyz-prompt-0</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>publishers/google/models/gemini-1.5-pro</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>0.3</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>BLOCK_NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           experiment_name                                   run_name  \\\n",
       "0  prompt-engineering-eval  eval-prompt-engineering-cisduk8n-prompt-1   \n",
       "1  prompt-engineering-eval  eval-prompt-engineering-cisduk8n-prompt-0   \n",
       "2  prompt-engineering-eval  eval-prompt-engineering-bqvcqujy-prompt-1   \n",
       "3  prompt-engineering-eval  eval-prompt-engineering-bqvcqujy-prompt-0   \n",
       "4  prompt-engineering-eval  eval-prompt-engineering-xo3pmfsw-prompt-2   \n",
       "5  prompt-engineering-eval  eval-prompt-engineering-xo3pmfsw-prompt-1   \n",
       "6  prompt-engineering-eval  eval-prompt-engineering-xo3pmfsw-prompt-0   \n",
       "7  prompt-engineering-eval  eval-prompt-engineering-7laouxyz-prompt-2   \n",
       "8  prompt-engineering-eval  eval-prompt-engineering-7laouxyz-prompt-1   \n",
       "9  prompt-engineering-eval  eval-prompt-engineering-7laouxyz-prompt-0   \n",
       "\n",
       "               run_type     state param.HARM_CATEGORY_UNSPECIFIED  \\\n",
       "0  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "1  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "2  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "3  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "4  system.ExperimentRun    FAILED                      BLOCK_NONE   \n",
       "5  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "6  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "7  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "8  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "9  system.ExperimentRun  COMPLETE                      BLOCK_NONE   \n",
       "\n",
       "                          param.model_name  \\\n",
       "0  publishers/google/models/gemini-1.5-pro   \n",
       "1  publishers/google/models/gemini-1.5-pro   \n",
       "2  publishers/google/models/gemini-1.5-pro   \n",
       "3  publishers/google/models/gemini-1.5-pro   \n",
       "4  publishers/google/models/gemini-1.5-pro   \n",
       "5  publishers/google/models/gemini-1.5-pro   \n",
       "6  publishers/google/models/gemini-1.5-pro   \n",
       "7  publishers/google/models/gemini-1.5-pro   \n",
       "8  publishers/google/models/gemini-1.5-pro   \n",
       "9  publishers/google/models/gemini-1.5-pro   \n",
       "\n",
       "  param.HARM_CATEGORY_DANGEROUS_CONTENT  param.temperature  \\\n",
       "0                            BLOCK_NONE                0.3   \n",
       "1                            BLOCK_NONE                0.3   \n",
       "2                            BLOCK_NONE                0.3   \n",
       "3                            BLOCK_NONE                0.3   \n",
       "4                            BLOCK_NONE                0.3   \n",
       "5                            BLOCK_NONE                0.3   \n",
       "6                            BLOCK_NONE                0.3   \n",
       "7                            BLOCK_NONE                0.3   \n",
       "8                            BLOCK_NONE                0.3   \n",
       "9                            BLOCK_NONE                0.3   \n",
       "\n",
       "  param.HARM_CATEGORY_SEXUALLY_EXPLICIT param.HARM_CATEGORY_HARASSMENT  ...  \\\n",
       "0                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "1                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "2                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "3                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "4                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "5                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "6                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "7                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "8                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "9                            BLOCK_NONE                     BLOCK_NONE  ...   \n",
       "\n",
       "  metric.fluency/mean metric.coherence/mean  \\\n",
       "0                 NaN                   NaN   \n",
       "1                 NaN                   NaN   \n",
       "2                 5.0              4.666667   \n",
       "3                 5.0              5.000000   \n",
       "4                 NaN                   NaN   \n",
       "5                 5.0              5.000000   \n",
       "6                 5.0              4.666667   \n",
       "7                 4.5              4.500000   \n",
       "8                 5.0              3.500000   \n",
       "9                 5.0              4.500000   \n",
       "\n",
       "   metric.summarization_quality/mean  metric.verbosity/std  \\\n",
       "0                                NaN                   NaN   \n",
       "1                                NaN                   NaN   \n",
       "2                           4.666667                   0.0   \n",
       "3                           5.000000                   0.0   \n",
       "4                                NaN                   NaN   \n",
       "5                           4.666667                   0.0   \n",
       "6                           5.000000                   0.0   \n",
       "7                           4.500000                   0.0   \n",
       "8                           3.500000                   0.0   \n",
       "9                           5.000000                   0.0   \n",
       "\n",
       "   metric.groundedness/mean  metric.groundedness/std  metric.verbosity/mean  \\\n",
       "0                       NaN                      NaN                    NaN   \n",
       "1                       NaN                      NaN                    NaN   \n",
       "2                       1.0                      0.0                    1.0   \n",
       "3                       1.0                      0.0                    1.0   \n",
       "4                       NaN                      NaN                    NaN   \n",
       "5                       1.0                      0.0                    1.0   \n",
       "6                       1.0                      0.0                    1.0   \n",
       "7                       1.0                      0.0                    1.0   \n",
       "8                       1.0                      0.0                    1.0   \n",
       "9                       1.0                      0.0                    1.0   \n",
       "\n",
       "   metric.summarization_quality/std  metric.fluency/std  metric.coherence/std  \n",
       "0                               NaN                 NaN                   NaN  \n",
       "1                               NaN                 NaN                   NaN  \n",
       "2                          0.577350            0.000000              0.577350  \n",
       "3                          0.000000            0.000000              0.000000  \n",
       "4                               NaN                 NaN                   NaN  \n",
       "5                          0.577350            0.000000              0.000000  \n",
       "6                          0.000000            0.000000              0.577350  \n",
       "7                          0.707107            0.707107              0.707107  \n",
       "8                          2.121320            0.000000              2.121320  \n",
       "9                          0.000000            0.000000              0.707107  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarization_eval_task.display_runs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1486e-b600-422a-b8e9-4ed6fa958763",
   "metadata": {},
   "source": [
    "### Model Based Metrics\n",
    "\n",
    "Now, suppose you do not have reference results or ground truths for your use case, you can evaluate and compare different models using another LLM. This technique is called **Model based evaluation**. Model-based metrics assesses your candidate model against a judge model. The judge model for most use cases is Gemini, but you can also use models such as [MetricX](https://github.com/google-research/metricx) or [COMET](https://huggingface.co/Unbabel/wmt22-comet-da) for translation use cases.\n",
    "\n",
    "You can measure model-based metrics pairwise or pointwise:\n",
    "\n",
    "- **Pointwise metrics**: Let the judge model assess the candidate model's output based on the evaluation criteria. For example, the score could be 0 to 5, where 0 means the response does not fit the criteria, while 5 means the response fits the criteria well.\n",
    "\n",
    "- **Pairwise metrics**: Let the judge model compare the responses of two models and pick the better one. This is often used when comparing a candidate model with the baseline model. Pairwise metrics are only supported with Gemini as a judge model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09bf14-05e1-4c3d-a176-02a2953f19fb",
   "metadata": {},
   "source": [
    "#### Pointwise Metrics\n",
    "\n",
    "Let's say now that we have decided on a prompt, we want to also rate the summaries generated on two qualitative criteria such as \"fluency\" and \"entertaining\". We will define a metric called `text_quality` using those two criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be534610-d0c8-4e0b-ad24-7397cec8109d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `input_variables` parameter is empty. Only the `response` column is used for computing this model-based metric.\n"
     ]
    }
   ],
   "source": [
    "# Your own definition of text_quality.\n",
    "metric_prompt_template = PointwiseMetricPromptTemplate(\n",
    "    criteria={\n",
    "        \"fluency\": \"Sentences flow smoothly and are easy to read, avoiding awkward phrasing or run-on sentences. Ideas and sentences connect logically, using transitions effectively where needed.\",\n",
    "        \"entertaining\": \"Short, amusing text that incorporates emojis, exclamations and questions to convey quick and spontaneous communication and diversion.\",\n",
    "    },\n",
    "    rating_rubric={\n",
    "        \"1\": \"The response performs well on both criteria.\",\n",
    "        \"0\": \"The response is somewhat aligned with both criteria\",\n",
    "        \"-1\": \"The response falls short on both criteria\",\n",
    "    },\n",
    ")\n",
    "\n",
    "text_quality = PointwiseMetric(\n",
    "    metric=\"text_quality\",\n",
    "    metric_prompt_template=metric_prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363820c9-664e-49a4-b562-50909541dacb",
   "metadata": {},
   "source": [
    "Let's take a look at the what this `text_quality` metric looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad56b490-3087-4c2e-9f17-3db01f95aaea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Instruction\n",
      "You are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models. We will provide you with the user prompt and an AI-generated responses.\n",
      "You should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.\n",
      "You will assign the response a rating following the Rating Rubric and Evaluation Steps. Give step by step explanations for your rating, and only choose ratings from the Rating Rubric.\n",
      "\n",
      "\n",
      "# Evaluation\n",
      "## Criteria\n",
      "entertaining: Short, amusing text that incorporates emojis, exclamations and questions to convey quick and spontaneous communication and diversion.\n",
      "fluency: Sentences flow smoothly and are easy to read, avoiding awkward phrasing or run-on sentences. Ideas and sentences connect logically, using transitions effectively where needed.\n",
      "\n",
      "## Rating Rubric\n",
      "-1: The response falls short on both criteria\n",
      "0: The response is somewhat aligned with both criteria\n",
      "1: The response performs well on both criteria.\n",
      "\n",
      "## Evaluation Steps\n",
      "Step 1: Assess the response in aspects of all criteria provided. Provide assessment according to each criterion.\n",
      "Step 2: Score based on the rating rubric. Give a brief rationale to explain your evaluation considering each individual criterion.\n",
      "\n",
      "\n",
      "# User Inputs and AI-generated Response\n",
      "## User Inputs\n",
      "\n",
      "\n",
      "\n",
      "## AI-generated Response\n",
      "{response}\n"
     ]
    }
   ],
   "source": [
    "print(text_quality.metric_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a0831-bfa1-4289-bdd6-9b60dc91994a",
   "metadata": {},
   "source": [
    "We will first need to get the responses from our model of interest (`gemini_1.5_pro`) and store it in a list. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8c6968-fc5f-4bcb-967b-0099fa36758e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemini_model = GenerativeModel(\n",
    "    \"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    ")\n",
    "\n",
    "context = [\n",
    "    \"To make a classic spaghetti carbonara, start by bringing a large pot of salted water to a boil. While the water is heating up, cook pancetta or guanciale in a skillet with olive oil over medium heat until it's crispy and golden brown. Once the pancetta is done, remove it from the skillet and set it aside. In the same skillet, whisk together eggs, grated Parmesan cheese, and black pepper to make the sauce. When the pasta is cooked al dente, drain it and immediately toss it in the skillet with the egg mixture, adding a splash of the pasta cooking water to create a creamy sauce.\",\n",
    "    \"Preparing a perfect risotto requires patience and attention to detail. Begin by heating butter in a large, heavy-bottomed pot over medium heat. Add finely chopped onions and minced garlic to the pot, and cook until they're soft and translucent, about 5 minutes. Next, add Arborio rice to the pot and cook, stirring constantly, until the grains are coated with the butter and begin to toast slightly. Pour in a splash of white wine and cook until it's absorbed. From there, gradually add hot chicken or vegetable broth to the rice, stirring frequently, until the risotto is creamy and the rice is tender with a slight bite.\",\n",
    "    \"For a flavorful grilled steak, start by choosing a well-marbled cut of beef like ribeye or New York strip. Season the steak generously with kosher salt and freshly ground black pepper on both sides, pressing the seasoning into the meat. Preheat a grill to high heat and brush the grates with oil to prevent sticking. Place the seasoned steak on the grill and cook for about 4-5 minutes on each side for medium-rare, or adjust the cooking time to your desired level of doneness. Let the steak rest for a few minutes before slicing against the grain and serving.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47afc5da-1539-4f5b-8f8a-c7d435223d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This article provides a concise guide to making classic spaghetti carbonara.  It details cooking pancetta or guanciale until crispy, then using the rendered fat to create a creamy sauce with eggs, Parmesan cheese, and black pepper. The cooked pasta is tossed directly into this sauce, with a touch of pasta water added for extra creaminess. \\n',\n",
       " 'Making perfect risotto is a labor of love! Start by sautéing onions and garlic in butter until softened.  Add Arborio rice and toast it lightly. Deglaze the pot with white wine, then gradually stir in hot broth until the risotto is creamy and the rice is cooked al dente. \\n',\n",
       " 'This article provides a concise guide to grilling a flavorful steak. It recommends selecting well-marbled cuts like ribeye or New York strip, seasoning generously with salt and pepper, and grilling over high heat for about 4-5 minutes per side for medium-rare doneness.  The article also emphasizes the importance of oiling the grill grates to prevent sticking and letting the steak rest before slicing. \\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = []\n",
    "instruction = \"Summarize the following article\"\n",
    "for article in context:\n",
    "    prompt = f\"Instruction: {instruction}. Article: {article}. Summary:\"\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    responses.append(response.text)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdbd2e57-402f-42ab-a3e2-b992aa1c30d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset = pd.DataFrame(\n",
    "    {\n",
    "        \"response\": responses,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb00332-690f-4b18-8190-9a4f5dee96c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-0a96e7ba-0a4a-4603-b1b2-eb95a5e2b2c5\" href=\"#view-view-vertex-resource-0a96e7ba-0a4a-4603-b1b2-eb95a5e2b2c5\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-0a96e7ba-0a4a-4603-b1b2-eb95a5e2b2c5');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/pointwise-eval/runs?project=sanjana-sandbox-012024');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/pointwise-eval/runs?project=sanjana-sandbox-012024', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/27138301346/locations/us-central1/metadataStores/default/contexts/pointwise-eval-1761bfc1-8735-44bf-9c58-264a96b61216 to Experiment: pointwise-eval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-12870b6a-0d22-4b14-81d3-759a08e61e06\" href=\"#view-view-vertex-resource-12870b6a-0d22-4b14-81d3-759a08e61e06\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-12870b6a-0d22-4b14-81d3-759a08e61e06');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/pointwise-eval/runs/pointwise-eval-1761bfc1-8735-44bf-9c58-264a96b61216?project=sanjana-sandbox-012024');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/pointwise-eval/runs/pointwise-eval-1761bfc1-8735-44bf-9c58-264a96b61216?project=sanjana-sandbox-012024', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics with a total of 3 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:11<00:00,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 metric requests are successfully computed.\n",
      "Evaluation Took:11.595499769988237 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"pointwise-eval\"\n",
    "eval_task = EvalTask(\n",
    "    dataset=eval_dataset, metrics=[text_quality], experiment=EXPERIMENT_NAME\n",
    ")\n",
    "\n",
    "pointwise_eval_results = eval_task.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a662f4d-8a04-4b0d-9427-2a378a1692d0",
   "metadata": {},
   "source": [
    "You can view the `summary_metrics` for all 3 articles here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04d1854a-e1bf-4ba5-b300-75688a25a5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_count': 3, 'text_quality/mean': 0.0, 'text_quality/std': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_eval_results.summary_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86e4d6-0628-4fbf-8322-636e27572ba5",
   "metadata": {},
   "source": [
    "We see that text_quality is `0.0` because based on the criteria we defined above the responses somewhat align with both creteria. To get the score for each article based on the criteria you defined in `text_quality` you can access the `metrics_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c19bde-88e6-43cc-9767-43c624ca364e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>text_quality/explanation</th>\n",
       "      <th>text_quality/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This article provides a concise guide to makin...</td>\n",
       "      <td>This response is not entertaining. It is infor...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making perfect risotto is a labor of love! Sta...</td>\n",
       "      <td>Step 1: Assessment based on criteria:\\n- enter...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This article provides a concise guide to grill...</td>\n",
       "      <td>The response is well-written, concise, and inf...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  This article provides a concise guide to makin...   \n",
       "1  Making perfect risotto is a labor of love! Sta...   \n",
       "2  This article provides a concise guide to grill...   \n",
       "\n",
       "                            text_quality/explanation  text_quality/score  \n",
       "0  This response is not entertaining. It is infor...                 0.0  \n",
       "1  Step 1: Assessment based on criteria:\\n- enter...                 0.0  \n",
       "2  The response is well-written, concise, and inf...                 0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointwise_eval_results.metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb72f54-f086-483e-9b0b-ee46cba78f9e",
   "metadata": {},
   "source": [
    "Based on the criteria we defined it looks like our model gave a neutral score for each of the summaries. You can see the rationale behind the models score in the `text_quality/explanation` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8c2d2-63c2-48bc-b3bb-c5d76653e95c",
   "metadata": {},
   "source": [
    "#### Pairwise Metrics - Compare Models Side-by-Side (SxS)\n",
    "\n",
    "Let's say now that we have decided on a prompt, we want to also rate the summaries generated from two different LLMs (Gemini 1.5 Pro vs Gemini 1.0 Pro). You can evaluate the summaries from two different models using pairwise model evaluation and side-by-side comparison.\n",
    "\n",
    "To directly compare two models, you can define a `PairwiseMetric` within an `EvalTask` run. This approach allows for a head-to-head assessment of the models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5319608-fdd0-4c19-9ade-f8aff154c501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"Summarize the following article\"\n",
    "prompt_template = \"{instruction}. Article: {context}. Summary:\"\n",
    "\n",
    "pairwise_eval_dataset = pd.DataFrame(\n",
    "    {\n",
    "        \"context\": context,\n",
    "        \"instruction\": [instruction] * len(context),\n",
    "        \"reference\": reference,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1cb2f5-95ff-43e3-af8a-efcd3f36df0e",
   "metadata": {},
   "source": [
    "Once we have prepared the evaluation dataset we will define the two models that we want to compare. `model_a` will be `gemini-1.0-pro` and `model_b` will be `gemini-1.5-pro`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "359ecb5f-71b7-4902-bb92-575b2a688eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Baseline model for pairwise comparison\n",
    "model_a = GenerativeModel(\n",
    "    \"gemini-1.0-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    ")\n",
    "\n",
    "# Candidate model for pairwise comparison\n",
    "model_b = GenerativeModel(\n",
    "    \"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab6aa6-e791-44df-a92c-30b27be710dd",
   "metadata": {},
   "source": [
    "Similar to how to defined the evaluation cretiria for pointwise evaluation above, you could customize your evaluation prompt. However, to save time, Vertex AI provides [predefined evaluation prompts](https://cloud.google.com/vertex-ai/generative-ai/docs/models/metrics-templates) in `MetricPromptTemplateExamples` you could use. In this use case, we are going to be evaluating the text quality between the two models. `pointwise_text_quality` will use the following criteria to evalute the model responses.\n",
    "\n",
    "```\n",
    "STEP 1: Analyze Response A based on all the Criteria provided, including Coherence, Fluency, Instruction following, Groundedness, and Verbosity. Provide assessment according to each criterion.\n",
    "STEP 2: Analyze Response B based on all the Criteria provided, including Coherence, Fluency, Instruction following, Groundedness, and Verbosity. Provide assessment according to each criterion \n",
    "STEP 3: Compare the overall performance of Response A and Response B based on your analyses and assessment of each criterion \n",
    "STEP 4: Output your preference of \"A\", \"SAME\" or \"B\" to the pairwise_choice field according to the Rating Rubric.\n",
    "STEP 5: Output your assessment reasoning in the explanation field, justifying your choice by highlighting the specific strengths and weaknesses of each response in terms of Text Quality\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c051748e-cd24-4b25-8a17-95e94b166b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a \"Pairwise Text Quality\" metric\n",
    "text_quality_prompt_template = MetricPromptTemplateExamples.get_prompt_template(\n",
    "    \"pairwise_text_quality\"\n",
    ")\n",
    "\n",
    "pairwise_text_quality_metric = PairwiseMetric(\n",
    "    metric=\"pairwise_text_quality\",\n",
    "    metric_prompt_template=text_quality_prompt_template,\n",
    "    baseline_model=model_a,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e78ed-de92-4156-afda-32b5c0b43f4f",
   "metadata": {},
   "source": [
    "Once we have defined the dataset and the evaluation crieteria. We are ready to kick off the evaluation job.\n",
    "\n",
    "Please note: the cell below is going to take 10-15 mins to finish execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3e7d63e-ea3c-4f90-bdf1-9cbf485e0a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-ffb201cd-3600-4553-b5ef-ff2922e68830\" href=\"#view-view-vertex-resource-ffb201cd-3600-4553-b5ef-ff2922e68830\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-ffb201cd-3600-4553-b5ef-ff2922e68830');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/pointwise-eval/runs?project=sanjana-sandbox-012024');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/pointwise-eval/runs?project=sanjana-sandbox-012024', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/27138301346/locations/us-central1/metadataStores/default/contexts/pointwise-eval-5798fa93-9f41-4cb5-a5b8-d799f732afc3 to Experiment: pointwise-eval\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-497b47f4-9d93-45c6-acce-a12b478609f2\" href=\"#view-view-vertex-resource-497b47f4-9d93-45c6-acce-a12b478609f2\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-497b47f4-9d93-45c6-acce-a12b478609f2');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/pointwise-eval/runs/pointwise-eval-5798fa93-9f41-4cb5-a5b8-d799f732afc3?project=sanjana-sandbox-012024');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/pointwise-eval/runs/pointwise-eval-5798fa93-9f41-4cb5-a5b8-d799f732afc3?project=sanjana-sandbox-012024', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Eval Experiment metadata: {'prompt_template': '{instruction}. Article: {context}. Summary:', 'model_name': 'publishers/google/models/gemini-1.5-pro', 'temperature': 0.3, 'HARM_CATEGORY_UNSPECIFIED': 'BLOCK_NONE', 'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE', 'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE', 'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE', 'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE'}\n",
      "Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
      "Generating a total of 3 responses from Gemini model gemini-1.5-pro.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 responses are successfully generated from Gemini model gemini-1.5-pro.\n",
      "Multithreaded Batch Inference took: 2.003985910996562 seconds.\n",
      "Generating a total of 3 responses from Gemini model gemini-1.0-pro.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 responses are successfully generated from Gemini model gemini-1.0-pro.\n",
      "Multithreaded Batch Inference took: 3.0498131430067588 seconds.\n",
      "Computing metrics with a total of 3 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 metric requests are successfully computed.\n",
      "Evaluation Took:11.469216444995254 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pairwise_text_quality_eval_task = EvalTask(\n",
    "    dataset=pairwise_eval_dataset,\n",
    "    metrics=[pairwise_text_quality_metric],\n",
    "    experiment=EXPERIMENT_NAME,\n",
    ")\n",
    "\n",
    "# Specify candidate model for pairwise comparison\n",
    "pairwise_text_quality_result = pairwise_text_quality_eval_task.evaluate(\n",
    "    model=model_b,\n",
    "    prompt_template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536f3057-785d-4f1b-8304-9cc78c2078c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the above experiment runs, you can view the results using the `display_eval_report` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e7a6675-d158-456a-8008-10dfc1d9768f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Side-by-side EvalTask"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Summary Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>pairwise_text_quality/candidate_model_win_rate</th>\n",
       "      <th>pairwise_text_quality/baseline_model_win_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_count  pairwise_text_quality/candidate_model_win_rate  \\\n",
       "0        3.0                                        0.333333   \n",
       "\n",
       "   pairwise_text_quality/baseline_model_win_rate  \n",
       "0                                       0.666667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Report Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>instruction</th>\n",
       "      <th>reference</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>baseline_model_response</th>\n",
       "      <th>pairwise_text_quality/explanation</th>\n",
       "      <th>pairwise_text_quality/pairwise_choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To make a classic spaghetti carbonara, start b...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>The process of making spaghetti carbonara invo...</td>\n",
       "      <td>Summarize the following article. Article: To m...</td>\n",
       "      <td>This article provides a concise guide to makin...</td>\n",
       "      <td>## Spaghetti Carbonara Summary:\\n\\n**Ingredien...</td>\n",
       "      <td>Response A is rated as significantly better th...</td>\n",
       "      <td>BASELINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preparing a perfect risotto requires patience ...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>Preparing risotto entails sautéing onions and ...</td>\n",
       "      <td>Summarize the following article. Article: Prep...</td>\n",
       "      <td>Making perfect risotto is a labor of love! Sta...</td>\n",
       "      <td>## Risotto Recipe Summary:\\n\\nThis summary out...</td>\n",
       "      <td>Response B provides a concise, well-written su...</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For a flavorful grilled steak, start by choosi...</td>\n",
       "      <td>Summarize the following article</td>\n",
       "      <td>Baking a decadent chocolate cake requires crea...</td>\n",
       "      <td>Summarize the following article. Article: For ...</td>\n",
       "      <td>To grill a flavorful steak, choose a well-marb...</td>\n",
       "      <td>## Grilling the Perfect Steak: A Summary\\n\\nTh...</td>\n",
       "      <td>Response A provides a more detailed and well-s...</td>\n",
       "      <td>BASELINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  To make a classic spaghetti carbonara, start b...   \n",
       "1  Preparing a perfect risotto requires patience ...   \n",
       "2  For a flavorful grilled steak, start by choosi...   \n",
       "\n",
       "                       instruction  \\\n",
       "0  Summarize the following article   \n",
       "1  Summarize the following article   \n",
       "2  Summarize the following article   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The process of making spaghetti carbonara invo...   \n",
       "1  Preparing risotto entails sautéing onions and ...   \n",
       "2  Baking a decadent chocolate cake requires crea...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Summarize the following article. Article: To m...   \n",
       "1  Summarize the following article. Article: Prep...   \n",
       "2  Summarize the following article. Article: For ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  This article provides a concise guide to makin...   \n",
       "1  Making perfect risotto is a labor of love! Sta...   \n",
       "2  To grill a flavorful steak, choose a well-marb...   \n",
       "\n",
       "                             baseline_model_response  \\\n",
       "0  ## Spaghetti Carbonara Summary:\\n\\n**Ingredien...   \n",
       "1  ## Risotto Recipe Summary:\\n\\nThis summary out...   \n",
       "2  ## Grilling the Perfect Steak: A Summary\\n\\nTh...   \n",
       "\n",
       "                   pairwise_text_quality/explanation  \\\n",
       "0  Response A is rated as significantly better th...   \n",
       "1  Response B provides a concise, well-written su...   \n",
       "2  Response A provides a more detailed and well-s...   \n",
       "\n",
       "  pairwise_text_quality/pairwise_choice  \n",
       "0                              BASELINE  \n",
       "1                             CANDIDATE  \n",
       "2                              BASELINE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_eval_report(\n",
    "    (\n",
    "        \"Side-by-side EvalTask\",\n",
    "        pairwise_text_quality_result.summary_metrics,\n",
    "        pairwise_text_quality_result.metrics_table,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ef80d4-48a5-446d-ae61-bca2e03c1439",
   "metadata": {},
   "source": [
    "All of the above evaluation experiments we ran in the notebook are accessible from the [Experiments Tab](https://console.cloud.google.com/vertex-ai/experiments/experiments) in the Vertex AI UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd0436-5f7b-43f1-9ca8-287b22929900",
   "metadata": {},
   "source": [
    "Copyright 2024 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "gemini_kernel",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "gemini_kernel (Local)",
   "language": "python",
   "name": "gemini_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
